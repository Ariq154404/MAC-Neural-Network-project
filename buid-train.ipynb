{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import os\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(\"numpy==\"+np.__version__)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(\"tensorflow==\"+tf.__version__)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(\"pandas==\"+pd.__version__)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(\"mlflow==\"+mlflow.__version__)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(mt\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "# print(\"numpy==\"+np.__version__)\n",
    "# print(\"tensorflow==\"+tf.__version__)\n",
    "# print(\"pandas==\"+pd.__version__)\n",
    "# print(\"mlflow==\"+mlflow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=10\n",
    "epochs=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Metal device set to: Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 20:16:10.280991: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-26 20:16:10.281262: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/4', experiment_id='4', lifecycle_stage='active', name='graph-neural-network-trial-batch-norm', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"graph-neural-network-trial-batch-norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def adjm(h,w,near):\n",
    "#   am=[[0 for i in range(w*h)] for j in range(h*w)]\n",
    "#   img=[[0 for i in range(w)] for j in range(h)]\n",
    "  \n",
    "#   dr=[[1,0],[0,1],[1,1],[-1,-1],[-1,0],[0,-1],[-1,1],[1,-1]]\n",
    "\n",
    "#   for i,v in enumerate(img):\n",
    "#     for j,v2 in enumerate(img[i]):\n",
    "#       timg=[[0 for i in range(w)] for j in range(h)]\n",
    "#       for k in range(0,near+1):\n",
    "#         for d in dr:\n",
    "#           posy=i+d[0]*k\n",
    "#           posx=j+d[1]*k\n",
    "#           if posy>=0 and posy<h and posx>=0 and posx<w:\n",
    "#             timg[posy][posx]=1\n",
    "#             am[i*w+j][posy*w+posx]=1\n",
    "#         print(timg)  \n",
    "\n",
    "#   return am\n",
    "\n",
    "# val=adjm(4,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train/x_train.pkl','rb') as f:\n",
    "        x1=pickle.load(f)\n",
    "with open('data/train/y_train.pkl','rb') as f:\n",
    "        y1=pickle.load( f)\n",
    "with open('data/valid/x_valid.pkl','rb') as f:\n",
    "        x2=pickle.load(f)\n",
    "with open('data/valid/y_valid.pkl','rb') as f:\n",
    "        y2=pickle.load( f)\n",
    "# with open('data/test/x_test.pkl','rb') as f:\n",
    "#         x3=pickle.load(f)\n",
    "# with open('data/test/y_test.pkl','rb') as f:\n",
    "#         y3=pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test/x_test.pkl','rb') as f:\n",
    "        x3=pickle.load(f)\n",
    "with open('data/test/y_test.pkl','rb') as f:\n",
    "        y3=pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 9, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "print(max(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(tf.keras.layers.Layer):\n",
    "    def __init__(self,inp_shape=9*12,out_shape=9*12,h=9, w=12,near=3):\n",
    "        super(GCN, self).__init__()\n",
    "        self.am=[[0 for i in range(w*h)] for j in range(h*w)]\n",
    "        self.img=[[0 for i in range(w)] for j in range(h)]\n",
    "  \n",
    "        self.dr=[[1,0],[0,1],[1,1],[-1,-1],[-1,0],[0,-1],[-1,1],[1,-1]]\n",
    "\n",
    "        for i,v in enumerate(self.img):\n",
    "           for j,v2 in enumerate(self.img[i]):\n",
    "        # timg=[[0 for i in range(w)] for j in range(h)]\n",
    "              for k in range(0,near+1):\n",
    "                for d in self.dr:\n",
    "                  posy=i+d[0]*k\n",
    "                  posx=j+d[1]*k\n",
    "                  if posy>=0 and posy<h and posx>=0 and posx<w:\n",
    "            # timg[posy][posx]=1\n",
    "                    self.am[i*w+j][posy*w+posx]=1\n",
    "        # print(timg) \n",
    "        self.am=np.array(self.am) \n",
    "        self.D = np.diag(np.sum(self.am, axis=0)) \n",
    "        self.Dinv=np.linalg.inv(self.D)\n",
    "        self.am=tf.Variable(self.am,trainable=True,dtype=tf.float32,name=\"ajm\")\n",
    "        self.Dinv=tf.Variable(self.Dinv,trainable=True,dtype=tf.float32,name=\"dm\")\n",
    "        # self.norm=tf.matmul(self.Dinv*self.am)\n",
    "        self.w = self.add_weight(\n",
    "            shape=(inp_shape, out_shape), initializer=\"random_normal\", trainable=True,dtype=tf.float32,name='adjw'\n",
    "        )\n",
    "        # self.b = self.add_weight(shape=(units,), initializer=\"zeros\", trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        inputs=tf.cast(inputs,dtype=tf.float32)\n",
    "        # inputs=tf.transpose()\n",
    "        print(inputs.shape)\n",
    "        # print(\"inpshape\",tf.transpose(inputs,perm=[1,0]).shape)\n",
    "        # print(self.Dinv.shape)\n",
    "        # print(self.am.shape)\n",
    "        # print(self.w.shape)\n",
    "        first_half=tf.matmul(inputs,tf.matmul(self.Dinv,self.am))\n",
    "    \n",
    "        return tf.matmul(first_half, self.w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(near=3,lay=2,bs=bs,n_out=7):\n",
    "    inputs = tf.keras.Input( shape=(9,12))\n",
    "    mlflow.log_param(\"layers\", lay)\n",
    "    mlflow.log_param(\"nearest\", near)\n",
    "    mlflow.set_tag(\"layer\", \"changed\")\n",
    "    print(inputs.shape)\n",
    "    # x=tf.reshape(inputs,[inputs.shape[1]*inputs.shape[2]],name=\"initial reshape\")\n",
    "    x=tf.keras.layers.Flatten()(inputs)\n",
    "    for i in range(lay):\n",
    "        x=GCN(near=near)(x)\n",
    "        x=tf.keras.layers.Activation('relu',name=\"graph_layer\"+str(i+1))(x)\n",
    "    x=tf.keras.layers.BatchNormalization()(x)\n",
    "    x=tf.keras.layers.Dense(units=32,activation=\"relu\",name=\"dense1\")(x)\n",
    "    output=tf.keras.layers.Dense(n_out,activation=\"softmax\",name=\"out_layer\")(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output, name=\"graph_neuralnetwork\")\n",
    "\n",
    "    model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 9, 12)\n",
      "(None, 108)\n",
      "(None, 108)\n"
     ]
    }
   ],
   "source": [
    "model=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"graph_neuralnetwork\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 9, 12)]           0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 108)               0         \n",
      "                                                                 \n",
      " gcn_2 (GCN)                 (None, 108)               34992     \n",
      "                                                                 \n",
      " graph_layer1 (Activation)   (None, 108)               0         \n",
      "                                                                 \n",
      " gcn_3 (GCN)                 (None, 108)               34992     \n",
      "                                                                 \n",
      " graph_layer2 (Activation)   (None, 108)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 108)              432       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32)                3488      \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,135\n",
      "Trainable params: 73,919\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"mode/base_model\",\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer GCN has arguments ['self', 'inp_shape', 'out_shape', 'h', 'w', 'near']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n",
      "Epoch 1/150\n",
      "(10, 108)\n",
      "(10, 108)\n",
      "(10, 108)\n",
      "(10, 108)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 20:24:48.284583: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 108)\n",
      "(10, 108)\n",
      "42/42 - 1s - loss: 2.0866 - accuracy: 0.1667 - val_loss: 157.1420 - val_accuracy: 0.1429 - 734ms/epoch - 17ms/step\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 20:24:48.688891: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 - 0s - loss: 1.9990 - accuracy: 0.1714 - val_loss: 10.0788 - val_accuracy: 0.1429 - 335ms/epoch - 8ms/step\n",
      "Epoch 3/150\n",
      "42/42 - 0s - loss: 1.8890 - accuracy: 0.2286 - val_loss: 2.6404 - val_accuracy: 0.1500 - 347ms/epoch - 8ms/step\n",
      "Epoch 4/150\n",
      "42/42 - 0s - loss: 1.8703 - accuracy: 0.2452 - val_loss: 2.7497 - val_accuracy: 0.1643 - 323ms/epoch - 8ms/step\n",
      "Epoch 5/150\n",
      "42/42 - 0s - loss: 1.8370 - accuracy: 0.2333 - val_loss: 2.4252 - val_accuracy: 0.1357 - 314ms/epoch - 7ms/step\n",
      "Epoch 6/150\n",
      "42/42 - 0s - loss: 1.7972 - accuracy: 0.2786 - val_loss: 4.2841 - val_accuracy: 0.1714 - 317ms/epoch - 8ms/step\n",
      "Epoch 7/150\n",
      "42/42 - 0s - loss: 1.8231 - accuracy: 0.2690 - val_loss: 2.7128 - val_accuracy: 0.1429 - 322ms/epoch - 8ms/step\n",
      "Epoch 8/150\n",
      "42/42 - 0s - loss: 1.7795 - accuracy: 0.2595 - val_loss: 7.6710 - val_accuracy: 0.1571 - 318ms/epoch - 8ms/step\n",
      "Epoch 9/150\n",
      "42/42 - 0s - loss: 1.8256 - accuracy: 0.2381 - val_loss: 4.5290 - val_accuracy: 0.1714 - 317ms/epoch - 8ms/step\n",
      "Epoch 10/150\n",
      "42/42 - 0s - loss: 1.7674 - accuracy: 0.2595 - val_loss: 4.1953 - val_accuracy: 0.1500 - 316ms/epoch - 8ms/step\n",
      "Epoch 11/150\n",
      "42/42 - 0s - loss: 1.7594 - accuracy: 0.2524 - val_loss: 2.8163 - val_accuracy: 0.1857 - 318ms/epoch - 8ms/step\n",
      "Epoch 12/150\n",
      "42/42 - 0s - loss: 1.7160 - accuracy: 0.2667 - val_loss: 4.3901 - val_accuracy: 0.1857 - 318ms/epoch - 8ms/step\n",
      "Epoch 13/150\n",
      "42/42 - 0s - loss: 1.7622 - accuracy: 0.2786 - val_loss: 3.0007 - val_accuracy: 0.1786 - 317ms/epoch - 8ms/step\n",
      "Epoch 14/150\n",
      "42/42 - 0s - loss: 1.7379 - accuracy: 0.2500 - val_loss: 2.5153 - val_accuracy: 0.1643 - 325ms/epoch - 8ms/step\n",
      "Epoch 15/150\n",
      "42/42 - 0s - loss: 1.7114 - accuracy: 0.3048 - val_loss: 2.3569 - val_accuracy: 0.1929 - 318ms/epoch - 8ms/step\n",
      "Epoch 16/150\n",
      "42/42 - 0s - loss: 1.7209 - accuracy: 0.2643 - val_loss: 4.5445 - val_accuracy: 0.1500 - 316ms/epoch - 8ms/step\n",
      "Epoch 17/150\n",
      "42/42 - 0s - loss: 1.6764 - accuracy: 0.3167 - val_loss: 2.6471 - val_accuracy: 0.1500 - 315ms/epoch - 8ms/step\n",
      "Epoch 18/150\n",
      "42/42 - 0s - loss: 1.6965 - accuracy: 0.3119 - val_loss: 5.6305 - val_accuracy: 0.1571 - 314ms/epoch - 7ms/step\n",
      "Epoch 19/150\n",
      "42/42 - 0s - loss: 1.7014 - accuracy: 0.2810 - val_loss: 2.3553 - val_accuracy: 0.2000 - 337ms/epoch - 8ms/step\n",
      "Epoch 20/150\n",
      "42/42 - 0s - loss: 1.7112 - accuracy: 0.3119 - val_loss: 6.6141 - val_accuracy: 0.1429 - 320ms/epoch - 8ms/step\n",
      "Epoch 21/150\n",
      "42/42 - 0s - loss: 1.6919 - accuracy: 0.3000 - val_loss: 1.9523 - val_accuracy: 0.2429 - 329ms/epoch - 8ms/step\n",
      "Epoch 22/150\n",
      "42/42 - 0s - loss: 1.6867 - accuracy: 0.3167 - val_loss: 8.8890 - val_accuracy: 0.1429 - 318ms/epoch - 8ms/step\n",
      "Epoch 23/150\n",
      "42/42 - 0s - loss: 1.6486 - accuracy: 0.3048 - val_loss: 2.7141 - val_accuracy: 0.1429 - 325ms/epoch - 8ms/step\n",
      "Epoch 24/150\n",
      "42/42 - 0s - loss: 1.7753 - accuracy: 0.2810 - val_loss: 36.1062 - val_accuracy: 0.1429 - 323ms/epoch - 8ms/step\n",
      "Epoch 25/150\n",
      "42/42 - 0s - loss: 1.8316 - accuracy: 0.2238 - val_loss: 15.6025 - val_accuracy: 0.1429 - 323ms/epoch - 8ms/step\n",
      "Epoch 26/150\n",
      "42/42 - 0s - loss: 1.7630 - accuracy: 0.3071 - val_loss: 15.8116 - val_accuracy: 0.1429 - 324ms/epoch - 8ms/step\n",
      "Epoch 27/150\n",
      "42/42 - 0s - loss: 1.8598 - accuracy: 0.2024 - val_loss: 5.0237 - val_accuracy: 0.1500 - 338ms/epoch - 8ms/step\n",
      "Epoch 28/150\n",
      "42/42 - 0s - loss: 1.7050 - accuracy: 0.2833 - val_loss: 4.0728 - val_accuracy: 0.1643 - 336ms/epoch - 8ms/step\n",
      "Epoch 29/150\n",
      "42/42 - 0s - loss: 1.6991 - accuracy: 0.2786 - val_loss: 3.3877 - val_accuracy: 0.1857 - 316ms/epoch - 8ms/step\n",
      "Epoch 30/150\n",
      "42/42 - 0s - loss: 1.6565 - accuracy: 0.3238 - val_loss: 4.0990 - val_accuracy: 0.1643 - 316ms/epoch - 8ms/step\n",
      "Epoch 31/150\n",
      "42/42 - 0s - loss: 1.6687 - accuracy: 0.3024 - val_loss: 2.7538 - val_accuracy: 0.1714 - 315ms/epoch - 7ms/step\n",
      "Epoch 32/150\n",
      "42/42 - 0s - loss: 1.6982 - accuracy: 0.3048 - val_loss: 7.9659 - val_accuracy: 0.1929 - 314ms/epoch - 7ms/step\n",
      "Epoch 33/150\n",
      "42/42 - 0s - loss: 1.6946 - accuracy: 0.2690 - val_loss: 8.3143 - val_accuracy: 0.1500 - 314ms/epoch - 7ms/step\n",
      "(None, 108)\n",
      "(None, 108)\n",
      "(None, 108)\n",
      "(None, 108)\n",
      "(None, 108)\n",
      "(None, 108)\n",
      "(None, 108)\n",
      "(None, 108)\n",
      "(None, 108)\n",
      "(None, 108)\n",
      "INFO:tensorflow:Assets written to: /var/folders/v9/13sg2_p569zdm3chj4w3dmr00000gn/T/tmpp9vruwy8/model/data/model/assets\n"
     ]
    }
   ],
   "source": [
    "# with mlflow.start_run(nested=true):\n",
    "history = model.fit(x1,y1, batch_size=bs, epochs=epochs, callbacks=[callback],validation_data=(x2,y2),verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/Users/ariqrahman/Desktop/Mac-Neural-Network-Project/model/')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ccd6447379f5e6f7b170904fd40d7e61f0af72b45d9bab3c3472de833a965dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
