{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import os\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"numpy==\"+np.__version__)\n",
    "# print(\"tensorflow==\"+tf.__version__)\n",
    "# print(\"pandas==\"+pd.__version__)\n",
    "# print(\"mlflow==\"+mlflow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=10\n",
    "epochs=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/4', experiment_id='4', lifecycle_stage='active', name='graph-neural-network-trial-batch-norm', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"graph-neural-network-trial-batch-norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def adjm(h,w,near):\n",
    "#   am=[[0 for i in range(w*h)] for j in range(h*w)]\n",
    "#   img=[[0 for i in range(w)] for j in range(h)]\n",
    "  \n",
    "#   dr=[[1,0],[0,1],[1,1],[-1,-1],[-1,0],[0,-1],[-1,1],[1,-1]]\n",
    "\n",
    "#   for i,v in enumerate(img):\n",
    "#     for j,v2 in enumerate(img[i]):\n",
    "#       timg=[[0 for i in range(w)] for j in range(h)]\n",
    "#       for k in range(0,near+1):\n",
    "#         for d in dr:\n",
    "#           posy=i+d[0]*k\n",
    "#           posx=j+d[1]*k\n",
    "#           if posy>=0 and posy<h and posx>=0 and posx<w:\n",
    "#             timg[posy][posx]=1\n",
    "#             am[i*w+j][posy*w+posx]=1\n",
    "#         print(timg)  \n",
    "\n",
    "#   return am\n",
    "\n",
    "# val=adjm(4,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train/x_train.pkl','rb') as f:\n",
    "        x1=pickle.load(f)\n",
    "with open('data/train/y_train.pkl','rb') as f:\n",
    "        y1=pickle.load( f)\n",
    "with open('data/valid/x_valid.pkl','rb') as f:\n",
    "        x2=pickle.load(f)\n",
    "with open('data/valid/y_valid.pkl','rb') as f:\n",
    "        y2=pickle.load( f)\n",
    "with open('data/test/x_test.pkl','rb') as f:\n",
    "        x3=pickle.load(f)\n",
    "with open('data/test/y_test.pkl','rb') as f:\n",
    "        y3=pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/test/x_test.pkl','rb') as f:\n",
    "#         x3=pickle.load(f)\n",
    "# with open('data/test/y_test.pkl','rb') as f:\n",
    "#         y3=pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31640, 9, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(max(y1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(tf.keras.layers.Layer):\n",
    "    def __init__(self,inp_shape=9*12,out_shape=9*12,h=9, w=12,near=3):\n",
    "        super(GCN, self).__init__()\n",
    "        self.am=[[0 for i in range(w*h)] for j in range(h*w)]\n",
    "        self.img=[[0 for i in range(w)] for j in range(h)]\n",
    "  \n",
    "        self.dr=[[1,0],[0,1],[1,1],[-1,-1],[-1,0],[0,-1],[-1,1],[1,-1]]\n",
    "\n",
    "        for i,v in enumerate(self.img):\n",
    "           for j,v2 in enumerate(self.img[i]):\n",
    "        # timg=[[0 for i in range(w)] for j in range(h)]\n",
    "              for k in range(0,near+1):\n",
    "                for d in self.dr:\n",
    "                  posy=i+d[0]*k\n",
    "                  posx=j+d[1]*k\n",
    "                  if posy>=0 and posy<h and posx>=0 and posx<w:\n",
    "            # timg[posy][posx]=1\n",
    "                    self.am[i*w+j][posy*w+posx]=1\n",
    "        # print(timg) \n",
    "        self.am=np.array(self.am) \n",
    "        self.D = np.diag(np.sum(self.am, axis=0)) \n",
    "        self.Dinv=np.linalg.inv(self.D)\n",
    "        self.am=tf.Variable(self.am,trainable=True,dtype=tf.float32)\n",
    "        self.Dinv=tf.Variable(self.Dinv,trainable=True,dtype=tf.float32)\n",
    "        # self.norm=tf.matmul(self.Dinv*self.am)\n",
    "        self.w = self.add_weight(\n",
    "            shape=(inp_shape, out_shape), initializer=\"random_normal\", trainable=True,dtype=tf.float32\n",
    "        )\n",
    "        # self.b = self.add_weight(shape=(units,), initializer=\"zeros\", trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs=tf.cast(inputs,dtype=tf.float32)\n",
    "    \n",
    "        # print(\"inpshape\",tf.transpose(inputs,perm=[1,0]).shape)\n",
    "        # print(self.Dinv.shape)\n",
    "        # print(self.am.shape)\n",
    "        # print(self.w.shape)\n",
    "        first_half=tf.matmul(inputs,tf.matmul(self.Dinv,self.am))\n",
    "    \n",
    "        return tf.matmul(first_half, self.w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(near=3,lay=2,bs=bs,n_out=7):\n",
    "    inputs = tf.keras.Input( shape=(9,12),\n",
    "    batch_size=bs)\n",
    "    mlflow.log_param(\"layers\", lay)\n",
    "    mlflow.log_param(\"nearest\", near)\n",
    "    mlflow.set_tag(\"layer\", \"changed\")\n",
    "    print(inputs.shape)\n",
    "    x=tf.reshape(inputs,[bs,inputs.shape[1]*inputs.shape[2]],name=\"initial reshape\")\n",
    "    for i in range(lay):\n",
    "        x=GCN(near=near)(x)\n",
    "        x=tf.keras.layers.Activation('relu',name=\"graph_layer\"+str(i+1))(x)\n",
    "    x=tf.keras.layers.BatchNormalization()(x)\n",
    "    x=tf.keras.layers.Dense(units=32,activation=\"relu\",name=\"dense1\")(x)\n",
    "    output=tf.keras.layers.Dense(n_out,activation=\"softmax\",name=\"out_layer\")(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output, name=\"graph_neuralnetwork\")\n",
    "\n",
    "    model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 9, 12)\n"
     ]
    }
   ],
   "source": [
    "model=build_model(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.41.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from shap) (1.22.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from shap) (1.0.2)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from shap) (2.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from shap) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from shap) (1.8.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from shap) (21.3)\n",
      "Requirement already satisfied: numba in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from shap) (0.55.2)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from shap) (4.64.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>20.9->shap) (3.0.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>4.25.0->shap) (0.4.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba->shap) (58.1.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba->shap) (0.38.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->shap) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->shap) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->shap) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5752505 , 0.66443235, 0.7418544 , ..., 0.73208207,\n",
       "         0.72718614, 0.6115528 ],\n",
       "        [0.7095544 , 0.7614971 , 0.82323956, ..., 0.7468288 ,\n",
       "         0.6086559 , 0.57828057],\n",
       "        [0.65374273, 0.75664425, 0.78604746, ..., 0.8213541 ,\n",
       "         0.73903996, 0.55480814],\n",
       "        ...,\n",
       "        [0.73330903, 0.8009314 , 0.5726006 , ..., 0.61182714,\n",
       "         0.65005016, 0.59027547],\n",
       "        [0.6853372 , 0.648102  , 0.38743198, ..., 0.6471534 ,\n",
       "         0.6059982 , 0.4590056 ],\n",
       "        [0.6011062 , 0.6863681 , 0.7520305 , ..., 0.6472004 ,\n",
       "         0.59428555, 0.5443106 ]],\n",
       "\n",
       "       [[0.67520815, 0.6957916 , 0.630137  , ..., 0.60860497,\n",
       "         0.7242462 , 0.7075905 ],\n",
       "        [0.7203341 , 0.6527196 , 0.61450446, ..., 0.52731395,\n",
       "         0.5978762 , 0.7086175 ],\n",
       "        [0.66256255, 0.595928  , 0.54497313, ..., 0.22062813,\n",
       "         0.24317151, 0.33333334],\n",
       "        ...,\n",
       "        [0.6823502 , 0.43245998, 0.5441813 , ..., 0.7343243 ,\n",
       "         0.59125155, 0.4315192 ],\n",
       "        [0.7108166 , 0.68730104, 0.70494455, ..., 0.7402512 ,\n",
       "         0.54621965, 0.45606565],\n",
       "        [0.69420403, 0.7108676 , 0.7363509 , ..., 0.73539835,\n",
       "         0.38163054, 0.4090738 ]],\n",
       "\n",
       "       [[0.64874876, 0.65463257, 0.67717594, ..., 0.6811233 ,\n",
       "         0.689947  , 0.67917114],\n",
       "        [0.6527157 , 0.6409599 , 0.4792676 , ..., 0.6556909 ,\n",
       "         0.6850942 , 0.6841181 ],\n",
       "        [0.68314207, 0.596908  , 0.36857724, ..., 0.6292786 ,\n",
       "         0.6400623 , 0.66260564],\n",
       "        ...,\n",
       "        [0.68529016, 0.6833341 , 0.6196395 , ..., 0.32371387,\n",
       "         0.45797467, 0.61673486],\n",
       "        [0.6294785 , 0.6686815 , 0.66672546, ..., 0.52269626,\n",
       "         0.55895936, 0.63246155],\n",
       "        [0.62756556, 0.66088873, 0.66873246, ..., 0.6040814 ,\n",
       "         0.6383845 , 0.64426833]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.6614885 , 0.7036314 , 0.68599576, ..., 0.5017875 ,\n",
       "         0.44397274, 0.38909796],\n",
       "        [0.68701494, 0.69779855, 0.6880027 , ..., 0.5449535 ,\n",
       "         0.5047784 , 0.43814385],\n",
       "        [0.67040235, 0.6851059 , 0.68510985, ..., 0.5930194 ,\n",
       "         0.5469644 , 0.4891497 ],\n",
       "        ...,\n",
       "        [0.6676506 , 0.6725544 , 0.66177857, ..., 0.68140554,\n",
       "         0.6872893 , 0.6275146 ],\n",
       "        [0.66083777, 0.67946124, 0.6735853 , ..., 0.69517225,\n",
       "         0.6853764 , 0.6422613 ],\n",
       "        [0.6569649 , 0.6618687 , 0.6775522 , ..., 0.6716998 ,\n",
       "         0.67562366, 0.65994793]],\n",
       "\n",
       "       [[0.5566309 , 0.56839454, 0.5674185 , ..., 0.5743058 ,\n",
       "         0.5654899 , 0.5547141 ],\n",
       "        [0.47631982, 0.56256175, 0.5566858 , ..., 0.58121264,\n",
       "         0.605716  , 0.5871004 ],\n",
       "        [0.5028263 , 0.51752985, 0.56065273, ..., 0.59203947,\n",
       "         0.5479444 , 0.54696834],\n",
       "        ...,\n",
       "        [0.54907334, 0.54809725, 0.55986094, ..., 0.5647882 ,\n",
       "         0.56479216, 0.5402967 ],\n",
       "        [0.5344207 , 0.53736454, 0.55108815, ..., 0.5177964 ,\n",
       "         0.55013955, 0.55112344],\n",
       "        [0.5089883 , 0.5285918 , 0.5423154 , ..., 0.53646296,\n",
       "         0.5501866 , 0.53647083]],\n",
       "\n",
       "       [[0.6007299 , 0.6046537 , 0.5928979 , ..., 0.6252646 ,\n",
       "         0.63212836, 0.6076329 ],\n",
       "        [0.6095967 , 0.60078084, 0.61058456, ..., 0.60767204,\n",
       "         0.6125758 , 0.59592015],\n",
       "        [0.5841644 , 0.6096477 , 0.61945134, ..., 0.6067391 ,\n",
       "         0.60086316, 0.6008671 ],\n",
       "        ...,\n",
       "        [0.60395205, 0.61277574, 0.61375964, ..., 0.5892877 ,\n",
       "         0.5677321 , 0.5853756 ],\n",
       "        [0.58537954, 0.5746037 , 0.62066656, ..., 0.6285338 ,\n",
       "         0.575619  , 0.5952224 ],\n",
       "        [0.5579872 , 0.60601   , 0.603074  , ..., 0.57664204,\n",
       "         0.5541065 , 0.5668501 ]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name each one of the classes\n",
    "class_names = ['MEL','NV','BCC','AKIEC','BKL','DF','VASC']\n",
    "# Save an example for each category in a dict\n",
    "images_dict = dict()\n",
    "for i, l in enumerate(y1):\n",
    "  # print(l)\n",
    "  index = l.tolist().index(1)\n",
    "  if len(images_dict)==7:\n",
    "    break\n",
    "  if index not in images_dict.keys():\n",
    "    images_dict[index] = x1[i].reshape((9, 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5752505"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_dict[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1080 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to plot images\n",
    "def plot_categories(images):\n",
    "  fig, axes = plt.subplots(1, 8, figsize=(16, 15))\n",
    "  axes = axes.flatten()\n",
    "  \n",
    "  # Plot an empty canvas\n",
    "  ax = axes[0]\n",
    "  dummy_array = np.array([[[0, 0, 0, 0]]], dtype='uint8')\n",
    "  ax.set_title(\"reference\")\n",
    "  ax.set_axis_off()\n",
    "  ax.imshow(dummy_array, interpolation='nearest')\n",
    "\n",
    "  # Plot an image for every category\n",
    "  for k,v in images.items():\n",
    "    ax = axes[k+1]\n",
    "    ax.imshow(v, cmap=plt.cm.binary)\n",
    "    ax.set_title(f\"{class_names[k]}\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "# Use the function to plot\n",
    "plot_categories(images_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31640"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a random sample of 5000 training images\n",
    "background = x1[np.random.choice(x1.shape[0], 5000, replace=False)]\n",
    "len(background[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Use DeepExplainer to explain predictions of the model\n",
    "e = shap.Explainer(model, background)\n",
    "\n",
    "# Compute shap values\n",
    "# shap_values = e.shap_values(x_test[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3demo = []\n",
    "for i in range(len(x3)):\n",
    "    supermain = []\n",
    "    for j in range(len(x3[i])):\n",
    "        main = []\n",
    "        for k in range(len(x3[i][j])):\n",
    "            main.append([x3[i][j][k]])\n",
    "        supermain.append(main)\n",
    "    x3demo.append(supermain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x3demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37239522"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: array([[0.37239522, 0.42139798, 0.5164597 , 0.6105414 , 0.54194695,\n",
      "        0.56743026, 0.6869914 , 0.5850777 , 0.53608274, 0.4282892 ,\n",
      "        0.5645099 , 0.5654938 ],\n",
      "       [0.5400183 , 0.52336264, 0.5704055 , 0.48123148, 0.6419516 ,\n",
      "        0.47927937, 0.5831609 , 0.57336503, 0.6468672 , 0.5880725 ,\n",
      "        0.55867714, 0.46264327],\n",
      "       [0.57730454, 0.56456876, 0.6753101 , 0.63317496, 0.5557607 ,\n",
      "        0.48618624, 0.6155471 , 0.72726846, 0.6077152 , 0.5048215 ,\n",
      "        0.57048386, 0.5567681 ],\n",
      "       [0.5469723 , 0.6253744 , 0.6577175 , 0.65772146, 0.55090785,\n",
      "        0.5509118 , 0.6528333 , 0.34414443, 0.59992236, 0.4725293 ,\n",
      "        0.60679007, 0.5548552 ],\n",
      "       [0.5773986 , 0.6881399 , 0.62542534, 0.60190976, 0.4098382 ,\n",
      "        0.61465734, 0.5607625 , 0.56370634, 0.6479883 , 0.6264327 ,\n",
      "        0.6636758 , 0.5872415 ],\n",
      "       [0.5225669 , 0.51375103, 0.60391283, 0.67447513, 0.58824104,\n",
      "        0.38342977, 0.52553034, 0.56375337, 0.67645466, 0.65293914,\n",
      "        0.5951244 , 0.5392696 ],\n",
      "       [0.5157541 , 0.67843425, 0.71763724, 0.594164  , 0.5588888 ,\n",
      "        0.6372909 , 0.65591437, 0.62847894, 0.5981035 , 0.61182714,\n",
      "        0.6657298 , 0.5814557 ],\n",
      "       [0.4579825 , 0.6177227 , 0.6314463 , 0.6108707 , 0.637334  ,\n",
      "        0.6833968 , 0.6853607 , 0.5599276 , 0.5952107 , 0.66087306,\n",
      "        0.54817957, 0.5403437 ],\n",
      "       [0.51780814, 0.5913103 , 0.5521152 , 0.59229815, 0.45608526,\n",
      "        0.65796447, 0.61582935, 0.5962337 , 0.5913378 , 0.5825219 ,\n",
      "        0.5247072 , 0.58350974]], dtype=float32), 2: array([[0.79672533, 0.7173511 , 0.76635385, 0.7702777 , 0.79968095,\n",
      "        0.7320664 , 0.80752856, 0.7477539 , 0.70855874, 0.70170283,\n",
      "        0.72718614, 0.7164103 ],\n",
      "       [0.72719395, 0.74091756, 0.77032083, 0.78110445, 0.75268906,\n",
      "        0.7164338 , 0.6987982 , 0.66450286, 0.68606627, 0.69782996,\n",
      "        0.7478127 , 0.77623594],\n",
      "       [0.7321409 , 0.76546407, 0.7595881 , 0.7458723 , 0.59593976,\n",
      "        0.53420514, 0.7047251 , 0.576352  , 0.48815796, 0.6625978 ,\n",
      "        0.6812213 , 0.68514514],\n",
      "       [0.74296767, 0.77041095, 0.70671636, 0.5450241 , 0.4930892 ,\n",
      "        0.5332722 , 0.4558579 , 0.2089076 , 0.5646432 , 0.5440676 ,\n",
      "        0.6695086 , 0.72341126],\n",
      "       [0.6969558 , 0.7312589 , 0.6734442 , 0.6215093 , 0.4431574 ,\n",
      "        0.44610125, 0.49412405, 0.25599355, 0.55489045, 0.5509745 ,\n",
      "        0.7508937 , 0.70091885],\n",
      "       [0.80088043, 0.728366  , 0.6950507 , 0.61371654, 0.5951009 ,\n",
      "        0.3697101 , 0.49319112, 0.3530583 , 0.23350503, 0.6803785 ,\n",
      "        0.7382011 , 0.7333051 ],\n",
      "       [0.779368  , 0.6372752 , 0.68333805, 0.65198267, 0.5285095 ,\n",
      "        0.47853458, 0.47951847, 0.54126096, 0.6951213 , 0.7549038 ,\n",
      "        0.73236823, 0.73237216],\n",
      "       [0.65397793, 0.6853411 , 0.7127844 , 0.6481098 , 0.6245943 ,\n",
      "        0.60499865, 0.49818507, 0.7079041 , 0.78336626, 0.7451511 ,\n",
      "        0.7578947 , 0.7030199 ],\n",
      "       [0.61580586, 0.6109099 , 0.7118515 , 0.7441946 , 0.73537874,\n",
      "        0.6863838 , 0.6618883 , 0.71481097, 0.65307635, 0.64426047,\n",
      "        0.6726837 , 0.5119714 ]], dtype=float32), 1: array([[0.59583   , 0.6467927 , 0.6781559 , 0.69089955, 0.68992347,\n",
      "        0.6556282 , 0.6752317 , 0.6742556 , 0.66837966, 0.65662384,\n",
      "        0.62428856, 0.6076329 ],\n",
      "       [0.65075576, 0.6909387 , 0.67526305, 0.68408674, 0.64293164,\n",
      "        0.61549616, 0.65959907, 0.69292223, 0.6743066 , 0.6694106 ,\n",
      "        0.6566748 , 0.64491904],\n",
      "       [0.65374273, 0.70568544, 0.66257036, 0.6116155 , 0.5214615 ,\n",
      "        0.14221428, 0.5400889 , 0.6949292 , 0.6870933 , 0.68219733,\n",
      "        0.6381023 , 0.6381062 ],\n",
      "       [0.6949488 , 0.7302319 , 0.7321958 , 0.69104064, 0.49014926,\n",
      "        0.4009753 , 0.43625838, 0.6244179 , 0.68126047, 0.698904  ,\n",
      "        0.6695086 , 0.6273735 ],\n",
      "       [0.7234152 , 0.727339  , 0.70480347, 0.68324786, 0.6107335 ,\n",
      "        0.5078398 , 0.4755045 , 0.54214686, 0.6470083 , 0.6950311 ,\n",
      "        0.6803354 , 0.63624036],\n",
      "       [0.70190275, 0.7264061 , 0.7146503 , 0.6970146 , 0.5314024 ,\n",
      "        0.44222838, 0.48927122, 0.5529736 , 0.67449474, 0.70585793,\n",
      "        0.6656828 , 0.6382473 ],\n",
      "       [0.6794103 , 0.7048936 , 0.728417  , 0.73038083, 0.676486  ,\n",
      "        0.43639556, 0.500098  , 0.58438   , 0.6549422 , 0.67944556,\n",
      "        0.65397006, 0.6275146 ],\n",
      "       [0.6657376 , 0.6500619 , 0.7078845 , 0.7088684 , 0.71769214,\n",
      "        0.6383179 , 0.56776345, 0.6647851 , 0.67556876, 0.6794926 ,\n",
      "        0.64323735, 0.60796213],\n",
      "       [0.6471651 , 0.65892875, 0.7059716 , 0.7089154 , 0.6883398 ,\n",
      "        0.69030374, 0.66090834, 0.65993226, 0.64915645, 0.62368095,\n",
      "        0.615845  , 0.6011493 ]], dtype=float32), 0: array([[0.509592  , 0.6056337 , 0.60367763, 0.59584177, 0.6634641 ,\n",
      "        0.6997272 , 0.6752317 , 0.65073615, 0.68013936, 0.6458441 ,\n",
      "        0.62428856, 0.5811735 ],\n",
      "       [0.5586379 , 0.6203804 , 0.63998383, 0.6174483 , 0.59001285,\n",
      "        0.6027565 , 0.6399995 , 0.67038274, 0.67920643, 0.63805133,\n",
      "        0.66353464, 0.6194396 ],\n",
      "       [0.58906424, 0.58808815, 0.45677516, 0.42933974, 0.51068175,\n",
      "        0.5910438 , 0.48423022, 0.5616523 , 0.61653495, 0.67239755,\n",
      "        0.6724015 , 0.62830645],\n",
      "       [0.5900912 , 0.57735544, 0.4911214 , 0.462706  , 0.5411081 ,\n",
      "        0.46761373, 0.44115826, 0.40294307, 0.4705654 , 0.5960064 ,\n",
      "        0.6616688 , 0.6528529 ],\n",
      "       [0.62737745, 0.63816106, 0.52938753, 0.41179422, 0.2726414 ,\n",
      "        0.36966303, 0.38632658, 0.3481114 , 0.38143453, 0.38927826,\n",
      "        0.6401563 , 0.64996004],\n",
      "       [0.6195846 , 0.6284084 , 0.40301755, 0.20016621, 0.1325517 ,\n",
      "        0.11687599, 0.24035703, 0.24722078, 0.17078649, 0.22958903,\n",
      "        0.48732695, 0.6362874 ],\n",
      "       [0.6215916 , 0.6607946 , 0.5814204 , 0.23941232, 0.18257758,\n",
      "        0.2942989 , 0.23746413, 0.43150353, 0.42268765, 0.447191  ,\n",
      "        0.5657721 , 0.611835  ],\n",
      "       [0.6284985 , 0.6294824 , 0.61968654, 0.598131  , 0.5991149 ,\n",
      "        0.56481963, 0.63244194, 0.6344058 , 0.62363   , 0.6657729 ,\n",
      "        0.6471573 , 0.61874187],\n",
      "       [0.63148546, 0.6158098 , 0.6334533 , 0.6559967 , 0.65012074,\n",
      "        0.6403249 , 0.6275891 , 0.6746319 , 0.6599362 , 0.6423005 ,\n",
      "        0.62858474, 0.59526944]], dtype=float32), 4: array([[0.7026475 , 0.5634947 , 0.56937844, 0.58800197, 0.6507244 ,\n",
      "        0.65660816, 0.64191246, 0.67523557, 0.7457979 , 0.7183624 ,\n",
      "        0.72130626, 0.72033024],\n",
      "       [0.63213617, 0.45182434, 0.50278705, 0.5821691 , 0.5880529 ,\n",
      "        0.63999563, 0.5870808 , 0.54886556, 0.5900285 , 0.5625931 ,\n",
      "        0.6664746 , 0.7027377 ],\n",
      "       [0.53222555, 0.4420716 , 0.50871396, 0.57241637, 0.5175416 ,\n",
      "        0.4489471 , 0.52538925, 0.532253  , 0.5224572 , 0.51462126,\n",
      "        0.5528443 , 0.5342286 ],\n",
      "       [0.61165076, 0.56559575, 0.49700126, 0.54992396, 0.45683005,\n",
      "        0.52935225, 0.4862372 , 0.4529219 , 0.50682455, 0.52838796,\n",
      "        0.55779123, 0.5372156 ],\n",
      "       [0.57837856, 0.49116454, 0.4892085 , 0.53331137, 0.52253556,\n",
      "        0.5303793 , 0.5254833 , 0.4970679 , 0.47747228, 0.5264751 ,\n",
      "        0.59801733, 0.5411826 ],\n",
      "       [0.5892054 , 0.6823071 , 0.48533562, 0.4618201 , 0.47554368,\n",
      "        0.5059269 , 0.50397086, 0.5500337 , 0.5578774 , 0.5441617 ,\n",
      "        0.57356495, 0.5539693 ],\n",
      "       [0.5784727 , 0.5863164 , 0.5226218 , 0.49518636, 0.5206697 ,\n",
      "        0.54713297, 0.62259513, 0.4618828 , 0.52558523, 0.5020697 ,\n",
      "        0.59321153, 0.6284946 ],\n",
      "       [0.6618177 , 0.61086285, 0.59420717, 0.59029114, 0.5785354 ,\n",
      "        0.6020587 , 0.44428635, 0.5217084 , 0.52367234, 0.578555  ,\n",
      "        0.6500972 , 0.6991    ],\n",
      "       [0.7255633 , 0.71968734, 0.7020517 , 0.69127584, 0.7206791 ,\n",
      "        0.6971636 , 0.5972098 , 0.5981937 , 0.61877716, 0.6609201 ,\n",
      "        0.7109028 , 0.7246264 ]], dtype=float32), 6: array([[0.75164634, 0.7722298 , 0.7692938 , 0.7692977 , 0.7791014 ,\n",
      "        0.793805  , 0.7987088 , 0.79675275, 0.8124363 , 0.8016605 ,\n",
      "        0.79382455, 0.7418897 ],\n",
      "       [0.78011274, 0.7781567 , 0.7693408 , 0.79580414, 0.80070794,\n",
      "        0.79189205, 0.8007158 , 0.8007197 , 0.8017036 , 0.7850479 ,\n",
      "        0.7683922 , 0.7429167 ],\n",
      "       [0.7586003 , 0.7625241 , 0.7811476 , 0.7654719 , 0.7831154 ,\n",
      "        0.79389906, 0.64886636, 0.7762673 , 0.77431124, 0.7929348 ,\n",
      "        0.78509885, 0.75178355],\n",
      "       [0.7478676 , 0.7527714 , 0.77923465, 0.76845884, 0.72926366,\n",
      "        0.7478872 , 0.75377095, 0.7782743 , 0.788078  , 0.77338225,\n",
      "        0.76848626, 0.734191  ],\n",
      "       [0.7577144 , 0.6499208 , 0.7410626 , 0.5284115 , 0.36573923,\n",
      "        0.44120136, 0.55684257, 0.77244145, 0.7832251 , 0.7685294 ,\n",
      "        0.7753932 , 0.7322781 ],\n",
      "       [0.7509016 , 0.7342459 , 0.7293499 , 0.5637377 , 0.43732458,\n",
      "        0.47750756, 0.670567  , 0.7617088 , 0.76759255, 0.75093687,\n",
      "        0.76956034, 0.7421249 ],\n",
      "       [0.5030144 , 0.7666322 , 0.770556  , 0.6098437 , 0.7431245 ,\n",
      "        0.760768  , 0.7705717 , 0.7813553 , 0.7823392 , 0.7529439 ,\n",
      "        0.76372755, 0.75393164],\n",
      "       [0.74119586, 0.7431598 , 0.75982326, 0.7637471 , 0.77649075,\n",
      "        0.8009941 , 0.7637589 , 0.7912021 , 0.7882661 , 0.705952  ,\n",
      "        0.7559347 , 0.74417895],\n",
      "       [0.7236033 , 0.6197297 , 0.76575017, 0.7824137 , 0.7990773 ,\n",
      "        0.77948165, 0.78046554, 0.7902692 , 0.7628338 , 0.75597787,\n",
      "        0.7540218 , 0.7344262 ]], dtype=float32), 5: array([[0.8280846 , 0.8192687 , 0.81731266, 0.7928172 , 0.7614618 ,\n",
      "        0.73598635, 0.7928289 , 0.8075325 , 0.7928368 , 0.7957806 ,\n",
      "        0.80460435, 0.80754817],\n",
      "       [0.7752128 , 0.6458598 , 0.74778134, 0.7526851 , 0.65077144,\n",
      "        0.69683427, 0.75661683, 0.7223215 , 0.75662464, 0.81346726,\n",
      "        0.80955124, 0.81053513],\n",
      "       [0.79387945, 0.6419869 , 0.7145091 , 0.59103596, 0.544001  ,\n",
      "        0.5214654 , 0.48717013, 0.6645499 , 0.6870933 , 0.78803486,\n",
      "        0.8125382 , 0.818422  ],\n",
      "       [0.82234585, 0.7488515 , 0.6841769 , 0.4930853 , 0.47740957,\n",
      "        0.4244947 , 0.4568379 , 0.50976056, 0.6783205 , 0.77730215,\n",
      "        0.7655464 , 0.8096492 ],\n",
      "       [0.8047533 , 0.7753579 , 0.49802828, 0.5225316 , 0.3794589 ,\n",
      "        0.69109553, 0.66855997, 0.5450868 , 0.57742995, 0.7557897 ,\n",
      "        0.7949927 , 0.80773634],\n",
      "       [0.7714811 , 0.7509055 , 0.5833333 , 0.4187011 , 0.55492187,\n",
      "        0.60588455, 0.62352806, 0.538274  , 0.47947928, 0.72447747,\n",
      "        0.81855917, 0.8313028 ],\n",
      "       [0.7852478 , 0.73331296, 0.7019576 , 0.5598648 , 0.6039677 ,\n",
      "        0.50989383, 0.46775874, 0.5089217 , 0.5696842 , 0.7509839 ,\n",
      "        0.8166463 , 0.8225301 ],\n",
      "       [0.779415  , 0.75491947, 0.7225842 , 0.61283064, 0.5305165 ,\n",
      "        0.5736394 , 0.55208385, 0.582467  , 0.6344097 , 0.748091  ,\n",
      "        0.7961138 , 0.7931778 ],\n",
      "       [0.782402  , 0.7873058 , 0.77359   , 0.66971636, 0.72753894,\n",
      "        0.7128432 , 0.6844278 , 0.7745896 , 0.7187348 , 0.74813807,\n",
      "        0.79322094, 0.7951848 ]], dtype=float32)}\n",
      "x_test_each_class tensor has shape: (7, 9, 12)\n"
     ]
    }
   ],
   "source": [
    "# Save an example of each class from the test set\n",
    "x_test_dict = dict()\n",
    "for i, l in enumerate(y3):\n",
    "  # print(l)\n",
    "  index = l.tolist().index(1)\n",
    "  if len(x_test_dict)==7:\n",
    "    break\n",
    "  if index not in x_test_dict.keys():\n",
    "    x_test_dict[index] = x3[i]\n",
    "print(x_test_dict)\n",
    "# Convert to list preserving order of classes\n",
    "x_test_each_class = [x_test_dict[i] for i in sorted(x_test_dict)]\n",
    "\n",
    "# Convert to tensor\n",
    "x_test_each_class = np.asarray(x_test_each_class)\n",
    "\n",
    "# Print shape of tensor\n",
    "print(f\"x_test_each_class tensor has shape: {x_test_each_class.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([3, 2, 1, 0, 4, 6, 5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.509592  , 0.6056337 , 0.60367763, 0.59584177, 0.6634641 ,\n",
       "         0.6997272 , 0.6752317 , 0.65073615, 0.68013936, 0.6458441 ,\n",
       "         0.62428856, 0.5811735 ],\n",
       "        [0.5586379 , 0.6203804 , 0.63998383, 0.6174483 , 0.59001285,\n",
       "         0.6027565 , 0.6399995 , 0.67038274, 0.67920643, 0.63805133,\n",
       "         0.66353464, 0.6194396 ],\n",
       "        [0.58906424, 0.58808815, 0.45677516, 0.42933974, 0.51068175,\n",
       "         0.5910438 , 0.48423022, 0.5616523 , 0.61653495, 0.67239755,\n",
       "         0.6724015 , 0.62830645],\n",
       "        [0.5900912 , 0.57735544, 0.4911214 , 0.462706  , 0.5411081 ,\n",
       "         0.46761373, 0.44115826, 0.40294307, 0.4705654 , 0.5960064 ,\n",
       "         0.6616688 , 0.6528529 ],\n",
       "        [0.62737745, 0.63816106, 0.52938753, 0.41179422, 0.2726414 ,\n",
       "         0.36966303, 0.38632658, 0.3481114 , 0.38143453, 0.38927826,\n",
       "         0.6401563 , 0.64996004],\n",
       "        [0.6195846 , 0.6284084 , 0.40301755, 0.20016621, 0.1325517 ,\n",
       "         0.11687599, 0.24035703, 0.24722078, 0.17078649, 0.22958903,\n",
       "         0.48732695, 0.6362874 ],\n",
       "        [0.6215916 , 0.6607946 , 0.5814204 , 0.23941232, 0.18257758,\n",
       "         0.2942989 , 0.23746413, 0.43150353, 0.42268765, 0.447191  ,\n",
       "         0.5657721 , 0.611835  ],\n",
       "        [0.6284985 , 0.6294824 , 0.61968654, 0.598131  , 0.5991149 ,\n",
       "         0.56481963, 0.63244194, 0.6344058 , 0.62363   , 0.6657729 ,\n",
       "         0.6471573 , 0.61874187],\n",
       "        [0.63148546, 0.6158098 , 0.6334533 , 0.6559967 , 0.65012074,\n",
       "         0.6403249 , 0.6275891 , 0.6746319 , 0.6599362 , 0.6423005 ,\n",
       "         0.62858474, 0.59526944]],\n",
       "\n",
       "       [[0.59583   , 0.6467927 , 0.6781559 , 0.69089955, 0.68992347,\n",
       "         0.6556282 , 0.6752317 , 0.6742556 , 0.66837966, 0.65662384,\n",
       "         0.62428856, 0.6076329 ],\n",
       "        [0.65075576, 0.6909387 , 0.67526305, 0.68408674, 0.64293164,\n",
       "         0.61549616, 0.65959907, 0.69292223, 0.6743066 , 0.6694106 ,\n",
       "         0.6566748 , 0.64491904],\n",
       "        [0.65374273, 0.70568544, 0.66257036, 0.6116155 , 0.5214615 ,\n",
       "         0.14221428, 0.5400889 , 0.6949292 , 0.6870933 , 0.68219733,\n",
       "         0.6381023 , 0.6381062 ],\n",
       "        [0.6949488 , 0.7302319 , 0.7321958 , 0.69104064, 0.49014926,\n",
       "         0.4009753 , 0.43625838, 0.6244179 , 0.68126047, 0.698904  ,\n",
       "         0.6695086 , 0.6273735 ],\n",
       "        [0.7234152 , 0.727339  , 0.70480347, 0.68324786, 0.6107335 ,\n",
       "         0.5078398 , 0.4755045 , 0.54214686, 0.6470083 , 0.6950311 ,\n",
       "         0.6803354 , 0.63624036],\n",
       "        [0.70190275, 0.7264061 , 0.7146503 , 0.6970146 , 0.5314024 ,\n",
       "         0.44222838, 0.48927122, 0.5529736 , 0.67449474, 0.70585793,\n",
       "         0.6656828 , 0.6382473 ],\n",
       "        [0.6794103 , 0.7048936 , 0.728417  , 0.73038083, 0.676486  ,\n",
       "         0.43639556, 0.500098  , 0.58438   , 0.6549422 , 0.67944556,\n",
       "         0.65397006, 0.6275146 ],\n",
       "        [0.6657376 , 0.6500619 , 0.7078845 , 0.7088684 , 0.71769214,\n",
       "         0.6383179 , 0.56776345, 0.6647851 , 0.67556876, 0.6794926 ,\n",
       "         0.64323735, 0.60796213],\n",
       "        [0.6471651 , 0.65892875, 0.7059716 , 0.7089154 , 0.6883398 ,\n",
       "         0.69030374, 0.66090834, 0.65993226, 0.64915645, 0.62368095,\n",
       "         0.615845  , 0.6011493 ]],\n",
       "\n",
       "       [[0.79672533, 0.7173511 , 0.76635385, 0.7702777 , 0.79968095,\n",
       "         0.7320664 , 0.80752856, 0.7477539 , 0.70855874, 0.70170283,\n",
       "         0.72718614, 0.7164103 ],\n",
       "        [0.72719395, 0.74091756, 0.77032083, 0.78110445, 0.75268906,\n",
       "         0.7164338 , 0.6987982 , 0.66450286, 0.68606627, 0.69782996,\n",
       "         0.7478127 , 0.77623594],\n",
       "        [0.7321409 , 0.76546407, 0.7595881 , 0.7458723 , 0.59593976,\n",
       "         0.53420514, 0.7047251 , 0.576352  , 0.48815796, 0.6625978 ,\n",
       "         0.6812213 , 0.68514514],\n",
       "        [0.74296767, 0.77041095, 0.70671636, 0.5450241 , 0.4930892 ,\n",
       "         0.5332722 , 0.4558579 , 0.2089076 , 0.5646432 , 0.5440676 ,\n",
       "         0.6695086 , 0.72341126],\n",
       "        [0.6969558 , 0.7312589 , 0.6734442 , 0.6215093 , 0.4431574 ,\n",
       "         0.44610125, 0.49412405, 0.25599355, 0.55489045, 0.5509745 ,\n",
       "         0.7508937 , 0.70091885],\n",
       "        [0.80088043, 0.728366  , 0.6950507 , 0.61371654, 0.5951009 ,\n",
       "         0.3697101 , 0.49319112, 0.3530583 , 0.23350503, 0.6803785 ,\n",
       "         0.7382011 , 0.7333051 ],\n",
       "        [0.779368  , 0.6372752 , 0.68333805, 0.65198267, 0.5285095 ,\n",
       "         0.47853458, 0.47951847, 0.54126096, 0.6951213 , 0.7549038 ,\n",
       "         0.73236823, 0.73237216],\n",
       "        [0.65397793, 0.6853411 , 0.7127844 , 0.6481098 , 0.6245943 ,\n",
       "         0.60499865, 0.49818507, 0.7079041 , 0.78336626, 0.7451511 ,\n",
       "         0.7578947 , 0.7030199 ],\n",
       "        [0.61580586, 0.6109099 , 0.7118515 , 0.7441946 , 0.73537874,\n",
       "         0.6863838 , 0.6618883 , 0.71481097, 0.65307635, 0.64426047,\n",
       "         0.6726837 , 0.5119714 ]],\n",
       "\n",
       "       [[0.37239522, 0.42139798, 0.5164597 , 0.6105414 , 0.54194695,\n",
       "         0.56743026, 0.6869914 , 0.5850777 , 0.53608274, 0.4282892 ,\n",
       "         0.5645099 , 0.5654938 ],\n",
       "        [0.5400183 , 0.52336264, 0.5704055 , 0.48123148, 0.6419516 ,\n",
       "         0.47927937, 0.5831609 , 0.57336503, 0.6468672 , 0.5880725 ,\n",
       "         0.55867714, 0.46264327],\n",
       "        [0.57730454, 0.56456876, 0.6753101 , 0.63317496, 0.5557607 ,\n",
       "         0.48618624, 0.6155471 , 0.72726846, 0.6077152 , 0.5048215 ,\n",
       "         0.57048386, 0.5567681 ],\n",
       "        [0.5469723 , 0.6253744 , 0.6577175 , 0.65772146, 0.55090785,\n",
       "         0.5509118 , 0.6528333 , 0.34414443, 0.59992236, 0.4725293 ,\n",
       "         0.60679007, 0.5548552 ],\n",
       "        [0.5773986 , 0.6881399 , 0.62542534, 0.60190976, 0.4098382 ,\n",
       "         0.61465734, 0.5607625 , 0.56370634, 0.6479883 , 0.6264327 ,\n",
       "         0.6636758 , 0.5872415 ],\n",
       "        [0.5225669 , 0.51375103, 0.60391283, 0.67447513, 0.58824104,\n",
       "         0.38342977, 0.52553034, 0.56375337, 0.67645466, 0.65293914,\n",
       "         0.5951244 , 0.5392696 ],\n",
       "        [0.5157541 , 0.67843425, 0.71763724, 0.594164  , 0.5588888 ,\n",
       "         0.6372909 , 0.65591437, 0.62847894, 0.5981035 , 0.61182714,\n",
       "         0.6657298 , 0.5814557 ],\n",
       "        [0.4579825 , 0.6177227 , 0.6314463 , 0.6108707 , 0.637334  ,\n",
       "         0.6833968 , 0.6853607 , 0.5599276 , 0.5952107 , 0.66087306,\n",
       "         0.54817957, 0.5403437 ],\n",
       "        [0.51780814, 0.5913103 , 0.5521152 , 0.59229815, 0.45608526,\n",
       "         0.65796447, 0.61582935, 0.5962337 , 0.5913378 , 0.5825219 ,\n",
       "         0.5247072 , 0.58350974]],\n",
       "\n",
       "       [[0.7026475 , 0.5634947 , 0.56937844, 0.58800197, 0.6507244 ,\n",
       "         0.65660816, 0.64191246, 0.67523557, 0.7457979 , 0.7183624 ,\n",
       "         0.72130626, 0.72033024],\n",
       "        [0.63213617, 0.45182434, 0.50278705, 0.5821691 , 0.5880529 ,\n",
       "         0.63999563, 0.5870808 , 0.54886556, 0.5900285 , 0.5625931 ,\n",
       "         0.6664746 , 0.7027377 ],\n",
       "        [0.53222555, 0.4420716 , 0.50871396, 0.57241637, 0.5175416 ,\n",
       "         0.4489471 , 0.52538925, 0.532253  , 0.5224572 , 0.51462126,\n",
       "         0.5528443 , 0.5342286 ],\n",
       "        [0.61165076, 0.56559575, 0.49700126, 0.54992396, 0.45683005,\n",
       "         0.52935225, 0.4862372 , 0.4529219 , 0.50682455, 0.52838796,\n",
       "         0.55779123, 0.5372156 ],\n",
       "        [0.57837856, 0.49116454, 0.4892085 , 0.53331137, 0.52253556,\n",
       "         0.5303793 , 0.5254833 , 0.4970679 , 0.47747228, 0.5264751 ,\n",
       "         0.59801733, 0.5411826 ],\n",
       "        [0.5892054 , 0.6823071 , 0.48533562, 0.4618201 , 0.47554368,\n",
       "         0.5059269 , 0.50397086, 0.5500337 , 0.5578774 , 0.5441617 ,\n",
       "         0.57356495, 0.5539693 ],\n",
       "        [0.5784727 , 0.5863164 , 0.5226218 , 0.49518636, 0.5206697 ,\n",
       "         0.54713297, 0.62259513, 0.4618828 , 0.52558523, 0.5020697 ,\n",
       "         0.59321153, 0.6284946 ],\n",
       "        [0.6618177 , 0.61086285, 0.59420717, 0.59029114, 0.5785354 ,\n",
       "         0.6020587 , 0.44428635, 0.5217084 , 0.52367234, 0.578555  ,\n",
       "         0.6500972 , 0.6991    ],\n",
       "        [0.7255633 , 0.71968734, 0.7020517 , 0.69127584, 0.7206791 ,\n",
       "         0.6971636 , 0.5972098 , 0.5981937 , 0.61877716, 0.6609201 ,\n",
       "         0.7109028 , 0.7246264 ]],\n",
       "\n",
       "       [[0.8280846 , 0.8192687 , 0.81731266, 0.7928172 , 0.7614618 ,\n",
       "         0.73598635, 0.7928289 , 0.8075325 , 0.7928368 , 0.7957806 ,\n",
       "         0.80460435, 0.80754817],\n",
       "        [0.7752128 , 0.6458598 , 0.74778134, 0.7526851 , 0.65077144,\n",
       "         0.69683427, 0.75661683, 0.7223215 , 0.75662464, 0.81346726,\n",
       "         0.80955124, 0.81053513],\n",
       "        [0.79387945, 0.6419869 , 0.7145091 , 0.59103596, 0.544001  ,\n",
       "         0.5214654 , 0.48717013, 0.6645499 , 0.6870933 , 0.78803486,\n",
       "         0.8125382 , 0.818422  ],\n",
       "        [0.82234585, 0.7488515 , 0.6841769 , 0.4930853 , 0.47740957,\n",
       "         0.4244947 , 0.4568379 , 0.50976056, 0.6783205 , 0.77730215,\n",
       "         0.7655464 , 0.8096492 ],\n",
       "        [0.8047533 , 0.7753579 , 0.49802828, 0.5225316 , 0.3794589 ,\n",
       "         0.69109553, 0.66855997, 0.5450868 , 0.57742995, 0.7557897 ,\n",
       "         0.7949927 , 0.80773634],\n",
       "        [0.7714811 , 0.7509055 , 0.5833333 , 0.4187011 , 0.55492187,\n",
       "         0.60588455, 0.62352806, 0.538274  , 0.47947928, 0.72447747,\n",
       "         0.81855917, 0.8313028 ],\n",
       "        [0.7852478 , 0.73331296, 0.7019576 , 0.5598648 , 0.6039677 ,\n",
       "         0.50989383, 0.46775874, 0.5089217 , 0.5696842 , 0.7509839 ,\n",
       "         0.8166463 , 0.8225301 ],\n",
       "        [0.779415  , 0.75491947, 0.7225842 , 0.61283064, 0.5305165 ,\n",
       "         0.5736394 , 0.55208385, 0.582467  , 0.6344097 , 0.748091  ,\n",
       "         0.7961138 , 0.7931778 ],\n",
       "        [0.782402  , 0.7873058 , 0.77359   , 0.66971636, 0.72753894,\n",
       "         0.7128432 , 0.6844278 , 0.7745896 , 0.7187348 , 0.74813807,\n",
       "         0.79322094, 0.7951848 ]],\n",
       "\n",
       "       [[0.75164634, 0.7722298 , 0.7692938 , 0.7692977 , 0.7791014 ,\n",
       "         0.793805  , 0.7987088 , 0.79675275, 0.8124363 , 0.8016605 ,\n",
       "         0.79382455, 0.7418897 ],\n",
       "        [0.78011274, 0.7781567 , 0.7693408 , 0.79580414, 0.80070794,\n",
       "         0.79189205, 0.8007158 , 0.8007197 , 0.8017036 , 0.7850479 ,\n",
       "         0.7683922 , 0.7429167 ],\n",
       "        [0.7586003 , 0.7625241 , 0.7811476 , 0.7654719 , 0.7831154 ,\n",
       "         0.79389906, 0.64886636, 0.7762673 , 0.77431124, 0.7929348 ,\n",
       "         0.78509885, 0.75178355],\n",
       "        [0.7478676 , 0.7527714 , 0.77923465, 0.76845884, 0.72926366,\n",
       "         0.7478872 , 0.75377095, 0.7782743 , 0.788078  , 0.77338225,\n",
       "         0.76848626, 0.734191  ],\n",
       "        [0.7577144 , 0.6499208 , 0.7410626 , 0.5284115 , 0.36573923,\n",
       "         0.44120136, 0.55684257, 0.77244145, 0.7832251 , 0.7685294 ,\n",
       "         0.7753932 , 0.7322781 ],\n",
       "        [0.7509016 , 0.7342459 , 0.7293499 , 0.5637377 , 0.43732458,\n",
       "         0.47750756, 0.670567  , 0.7617088 , 0.76759255, 0.75093687,\n",
       "         0.76956034, 0.7421249 ],\n",
       "        [0.5030144 , 0.7666322 , 0.770556  , 0.6098437 , 0.7431245 ,\n",
       "         0.760768  , 0.7705717 , 0.7813553 , 0.7823392 , 0.7529439 ,\n",
       "         0.76372755, 0.75393164],\n",
       "        [0.74119586, 0.7431598 , 0.75982326, 0.7637471 , 0.77649075,\n",
       "         0.8009941 , 0.7637589 , 0.7912021 , 0.7882661 , 0.705952  ,\n",
       "         0.7559347 , 0.74417895],\n",
       "        [0.7236033 , 0.6197297 , 0.76575017, 0.7824137 , 0.7990773 ,\n",
       "         0.77948165, 0.78046554, 0.7902692 , 0.7628338 , 0.75597787,\n",
       "         0.7540218 , 0.7344262 ]]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_each_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 9, 12)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x3[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "750*9*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions\n",
    "predictions = model.predict(x3[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Apply argmax to get predicted class\n",
    "np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'warnings' has no attribute 'DeprecationWarning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\projects\\python\\Mac-Neural-Network-Project\\buid_train.ipynb Cell 37'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/python/Mac-Neural-Network-Project/buid_train.ipynb#ch0000033?line=0'>1</a>\u001b[0m \u001b[39m# Compute shap values using DeepExplainer instance\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/projects/python/Mac-Neural-Network-Project/buid_train.ipynb#ch0000033?line=1'>2</a>\u001b[0m shap_values \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39;49mshap_values(x_test_each_class)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_permutation.py:214\u001b[0m, in \u001b[0;36mPermutation.shap_values\u001b[1;34m(self, X, npermutations, main_effects, error_bounds, batch_evals, silent)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshap_values\u001b[39m(\u001b[39mself\u001b[39m, X, npermutations\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, main_effects\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, error_bounds\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, batch_evals\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, silent\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    191\u001b[0m     \u001b[39m\"\"\" Legacy interface to estimate the SHAP values for a set of samples.\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39m        of such matrices, one for each output.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mshap_values() is deprecated; use __call__().\u001b[39m\u001b[39m\"\u001b[39m, warnings\u001b[39m.\u001b[39;49mDeprecationWarning)\n\u001b[0;32m    216\u001b[0m     explanation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(X, max_evals\u001b[39m=\u001b[39mnpermutations \u001b[39m*\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], main_effects\u001b[39m=\u001b[39mmain_effects)\n\u001b[0;32m    217\u001b[0m     \u001b[39mreturn\u001b[39;00m explanation\u001b[39m.\u001b[39mvalues\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'warnings' has no attribute 'DeprecationWarning'"
     ]
    }
   ],
   "source": [
    "# Compute shap values using DeepExplainer instance\n",
    "shap_values = e.shap_values(x_test_each_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHgAAACiCAYAAAA6GHoZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAd90lEQVR4nO3de3Cc9X3v8c9Xlqy7ZFnGRsbCNr4MxtSAb4CJBww5w5gC9lBIDSfgcMvkTIGeJiQhbeYUMtDTBtqUHEg6KYHYQJqEgiEEAqWmjSHm5gJ2ANvIN3y3JMu63+Xf+WNXjVBs8/0Z1vIjvV8zmoTdt9aPVs8+z7PffXZlIQQBAAAAAAAgubIGegEAAAAAAADw6TDgAQAAAAAASDgGPAAAAAAAAAnHgAcAAAAAACDhGPAAAAAAAAAkHAMeAAAAAACAhBsSAx4zG2Nmq8ysycz+fqCXBwAAAAAA4LOUPdALcIx8WVKtpJIQQhjohQEAAAAAAPgsDYozeMzskwZV4yV9cDTDHcdtAwAAAAAADKjEDnjMbJuZfdPM1klqMbPPmdlqM6s3s7VmdkG6+4mkpZK+YWbNZvZ5M8syszvMbLOZ7TezX5jZyHQ/wcyCmd1oZtslvZy+/AYzW29mB8zsRTMb32dZgpl9xcyq0v/+g2Zmfa6/Of29TWb2gZnNTF8+1syeNLMaM9tqZrcdo7sPAAAAAAAMIokd8KRdLemPJZ0i6RlJd0saKel2SU+a2QkhhC9JelzSd0MIRSGEf5d0q6TFks6XNFbSAUkP9rvt8yVNk3SxmS2S9JeSrpB0gqRXJP1Lv/5SSXMkzZD0BUkXS5KZXSXpTknXSSqRdLmk/WaWJelZSWslnSTpIkn/28wu/pT3CQAAAAAAGGKSPuD5fghhh6QvSno+hPB8COFgCOElSWskXXKY7/uKpL8KIewMIXQoNYC5st/bse4MIbSEENrS/f8NIawPIXRL+htJZ/Y9i0fS34YQ6kMI2yX9h6Qz05ffpNRw6a2QsimE8JFSw6ATQgjfCSF0hhC2SPpnSUs+/d0CAAAAAACGkqR/vsyO9P+Ol3SVmV3W57ocpQYthzJe0gozO9jnsh5JYw5x2739/f3+ApcpdebNR+n/3tvnulZJRen/Xylp82GWYayZ1fe5bJhSZwcBAAAAAAC4JX3A0/uhyTskPRpCuNn5fTsk3RBC+G3/K8xsQr/b7u3vCSE8fhTLuEPSpMNcvjWEMOUobhMAAAAAAOC/Jf0tWr0ek3SZmV1sZsPMLM/MLjCzcYfp/0nSPb1vsTKzE9Kfs3M4/yTpW2Y2Pd2Xpj9bx+MhSbeb2SxLmZz+d9+U1JT+oOj89HKfbmZznLcLAAAAAAAgaZAMeNKfw9P7Qcg1Sp0d83Ud/ue7X9IvJf2bmTVJel3S2Ue4/RWS/k7Sz8ysUdJ7khY6l+0JSfdI+qmkJklPSxoZQuhR6oOZz5S0VVKtUsOgUs/tAgAAAAAA9LIQwidXAAAAAAAAOG4NijN4AAAAAAAAhjIGPAAAAAAAAAnHgAcAAAAAACDhGPAAAAAAAAAkHAMeAAAAAACAhGPAAwAAAAAAkHAMeAAAAAAAABKOAQ8Qycy2mVmnmY3qd/k7ZhbMbIKZ/STdNPf5WpvuJqS77IH5CXA8SK9H1WZW2Oeym8zsP81sg5ndcIjv+XMzW3NslxQDLb2utKW3IwfM7Dkzq+xz/TVmtiZ9/R4z+7WZfa7P9VPN7AkzqzWzBjNbZ2ZfNbNhA/MTIVPS248DZpbb57KfmNndff57eno9uT3939vM7PPp//8lM+vpt+9qNrOxfb7/iOsbBocjbXdi1ikMbX3WoyYzqzez1Wb2FTPLSl9/qOPlPx3o5UZmmdkLZvadQ1y+yMz2mlm2mV2Qfr70zUN0N6aPlZvMbJ+ZPW9mxX2un5u+rN7M6szsTTO7PtM/1/GCAQ9wdLZKurr3P8zsjyQV9Gu+G0Io6vN1xjFdQiTBMEl/fojLl0m67hCXX5u+DkPPZSGEIkkVkvZJ+n+SZGZflfSPkv5G0hhJJ0v6gaRF6esnSXpD0g5JfxRCKJV0laTZkoqFQcPMJkiaLylIuvwwzVmS/kPS3SGE+w5zU6/123cVhRB2p7//iOsbBp1Dbnf6cq5TGNouCyEUSxov6W8lfVPSj/tc3/94+ecDspQ4lpZJ+qKZWb/Lr5X0eAihW9JSSXXqdzxsZucrtQ+6Or1eTZP08z7XnyvpZUm/kTRZUrmk/yVpYWZ+lOMPAx7g6Dyqj29wlkpaPkDLguS6V9LtZjai3+WPSvqcmY3vvcDMTpM0Q9K/HLvFw/EmhNAu6V8lnWZmpZK+I+nPQghPhRBaQghdIYRnQwhfT3/LXZJWhxC+GkLYk76NjSGEa0II9QPyQyBTrpP0uqSfKLVP+hgzmyvpJUl/GUJ4MPbGnesbBqG+252+l3/adQpDSwihIYTwS0l/KmmpmZ0+0MuEAfO0UoOX+b0XmFmZpEslLU+f3X6lpD+TNMXMZvf53jlKvRDxjiSFEOpCCMtCCE3p6++VtCyE8HchhNqQ8l8hhC9k/sc6PjDgAY7O65JKzGxa+m0OSyQ9NsDLhORZI+k/Jd3e98IQwk6lXhG9ts/F10p6PoRQe8yWDscdMytQ6uD4dUnnSsqTtOII3/J5pZ6YYfC7TtLj6a+LzWxMn+vmSnpB0l+EEB46ytv3rG8YhPptd3p9FusUhqAQwpuSdqrPk3sMLSGENkm/0MdfLP+CpA0hhLWSrpDULOkJSS/q4y9avKHUPu4uMzuv31uSC5TaVw3p4x4GPMDR6z2L539IWi9pV7/rb0+/97P3i7fW4FD+j6RbzeyEfpcvU3rAk36v+v8Ub88ayp42s3pJDUptc+5V6tWv2vSpzIdTLmlP5hcPAyn9GTjjJf0ihPBfkjZLuqZPco5S686vHTd3Tr991+b05Z71DYPLobY7vWLWKaC/3ZJGpv9/3+NlXsQaOpZJutLM8tL/fZ1+f5y7VNLPQwg9kn4qaYmZ5UhSCOEVpQZAMyU9J2m/mf1D+gX3MqXmG0P6uIcBD3D0HlXqAPpLOvTbs+4LIYzo8/UHp8wDIYT3JP1K0h39rnpKUoWZnSPpAqU+4+m5Y7t0OI4sDiGMUOoMiluUem95j6RRduQPbN+v1OdnYHBbKunf+pzh91N9/BXPB5U6Y/Cl9GnwR/J6v33XpPTl+/XJ6xsGlz/Y7pjZienrYtYpoL+TlPp8Fenjx8ujjvRNGDxCCK9KqpW0OP15gXMl/TT9Ye4LlDobVZKeUWob9Md9vvfXIYTLlBoSLlLqudhNkg5IOqghftzDgAc4SiGEj5T6sOVLlHoyDhytv5Z0s1IHPJKkEEKrUqeYXqfUmTw/CyF0Dszi4XgRQugJITyl1HAnV1KHpMVH+JZ/l/Qnx2DRMEDMLF+pU9vPT//1kb2S/kLSGWbW++H+PUq9ILFd0otmVnIU/9Rr+uT1DYNQv+1O719M+yzWKQxBZjZHqeOdVwd6WTDglit1nPtFSS+GEPYpdcybJenZ9P5si1IDnj94oTyEcDCEsFKpD1U+PX3s/JqG+HEPAx7g07lR0oUhhJaj+N5cM8vr88XjcYgKIWxS6i8A3NbvqmVKfe7Bn4i3Z0GSpSxS6jTkNUq9xe9BM1tsZgVmlmNmC83su+lv+WtJ88zs3t5X3s1sspk9dogP90YyLVbqyfZpks5Mf02T9Ir6fL5BCKFLqb+gVivp+fSHWLqFEBr0yesbBqF+2531vZd/wjqV0+8YhzO/hjgzKzGzSyX9TNJjIYTfDfQyYcAtV+qzAm/Wx9+edZd+vz87U6nj4EvMrDz9p9SXmFlZets0V9L5+v1nhH1D0pfM7OtmVi5JZnaGmf3sGP1MA44nlMCnEELYHEJYc5irv2FmzX2++r+vuFlSW5+vCzO5rDjufUdS/ydcq5T6jIOdIYS3jv0i4TjyrJk1S2qUdI+kpSGE90MIfy/pq5K+LalGqT+HfotSf6FCIYTNSn3g4ARJ75tZg6QnlRoONQmDwVJJj4QQtocQ9vZ+SXpAqc/u+u8n1umzAK+Q1K7UOpV/iNs7t9++qzn9irs+aX3DoHPI7U7f4Ajr1PP6+DHOncdqoXHcedbMmpTaXvyVpH+QdP3ALhKOByGEbZJWK3X8+8v0xxKMl/Rg3/1Z+q+vbZJ0tVJvw7pZUpVS26bHJN0bQng8fZurlXpOdaGkLWZWJ+lHSm2ThgQLIQz0MgAAAAAAAOBT4AweAAAAAACAhGPAAwAAAAAAkHAMeAAAAAAAABKOAQ8AAAAAAEDC8ScLkRGnnnqq+9O729vb3bfb09Pjbjs7O92tmbnbjo4Od5uXl5eR2y0oKHC3zc3N7jbmPisuLna3+/btc93B48aNc683bW1t7n8/RszvISvLPyPv7u52t5n62WLWx5h1IT//UH+I59Bi7rPGxkb3A/O+++5zrzu5ubnuZdizZ4+7zZTS0lJ329XV5W5PPvlkd5uTk+NuGxsb3e3YsWPdbUtLi7tdsmSJe935zW9+4153rrjiCvcyxDyOY9qioiJ3W1FR4W4nT57sbmOWN2bbt3v3bnc7YsQIdztjxgx3+8gjj7jWnSuuuMK93rzwwgvuf//KK690t2+++aa7jTnOiXm8x6yPTU3+P9x30UUXudv333//k6O0mH3QiSee6G6XLVvmvoOXLl3qXnfWrVvnXobZs2e727Vr17rbmOO9cePGudtVq1a525jjl+xs/9PbmPW3rKzM3dbU1Ljbt956y73uXHLJJe51Z/369e5laG1tdbfnnXeeu928ebO7nThxorvdtGmTuy0s7P8Hag+vpKTE3e7du9fdTpkyxd02NDS425UrVx5y3eEMHgAAAAAAgIRjwAMAAAAAAJBwDHgAAAAAAAASjgEPAAAAAABAwjHgAQAAAAAASDgGPAAAAAAAAAnHgAcAAAAAACDhGPAAAAAAAAAkHAMeAAAAAACAhGPAAwAAAAAAkHDZA70AGJwaGxvdbXt7u7stKChwt8OHD3e3hYWF7nbhwoXu9v3333e327dvd7cdHR3udtiwYe62pKTE3XZ2drpbr+xs/yYppi0vL3e3O3fudLe5ubnu9uDBg+425mfLyvLP6Xt6etxtzGNixIgR7jYT640ktba2uts1a9a423Xr1rnbq666yt3W1NS42+XLl7vbG264wd3u2rXL3VZUVLjbUaNGudvm5mZ3O3LkSHcb47bbbnO3XV1d7jaE4G7HjRvnbnNyctxtzPLG7ItnzJjhbletWuVu77///oy0VVVV7tbr1VdfdbdLlixxt1u3bnW3GzdudLeLFy92tzHbhtGjR7vbmH1QUVGRu405znnhhRfcbWVlpbuNEfM7jrnP3n77bXcbsx2JOabftm2bu83Ly3O3MfuKsrIyd1tXV+dui4uL3W3M8WGMMWPGZOR2Y9azmJ8tZl+xadMmdzt79mx3+9RTT7nbOXPmuNuYY52WlhZ3G7N9OBzO4AEAAAAAAEg4BjwAAAAAAAAJx4AHAAAAAAAg4RjwAAAAAAAAJBwDHgAAAAAAgIRjwAMAAAAAAJBwDHgAAAAAAAASjgEPAAAAAABAwjHgAQAAAAAASDgGPAAAAAAAAAmXPdALgMEphOBuzczdFhcXu9tx48a5229961vutrW11d2eddZZ7ra9vd3djhw50t3ed9997ra6utrdFhQUuFuv/Px8d9vd3e1uY35nJ5xwgrvNzvZvQnNzc93twYMH3W1tba277enpcbctLS3utq6uzt1mZWXmdYWYdbezs9Pdzpgxw92uW7fO3cb8jufNm+dui4qK3G3MtnfEiBHuNkZhYaG7HT16dEaWobKy0t3GrGfNzc3uNmafGXO78+fPd7cVFRXutrGx0d2WlZW520ceecTdLlq0yN2++OKL7tZr5syZ7nbFihXutrS01N2ee+657vall15ytzHrzSmnnOJuy8vL3W1DQ4O7/eijj9ztwoUL3e2VV17pbmOMHTvW3dbX17vbmO3I3Llz3e2bb77pbmP2baNGjXK3MWK2TzHHZh0dHe42Zjsdo6qqyt1OnTrV3cb8jtva2txtzPOVBQsWuNuYx8UNN9zgbmMeQzH3Wczyzpo1y90eDmfwAAAAAAAAJBwDHgAAAAAAgIRjwAMAAAAAAJBwDHgAAAAAAAASjgEPAAAAAABAwjHgAQAAAAAASDgGPAAAAAAAAAnHgAcAAAAAACDhGPAAAAAAAAAkHAMeAAAAAACAhMse6AXA4NTT0+Nus7P9q+GECRPc7b333puR2+3o6HC3DzzwgLu96aab3G1ZWZm7nTFjhru99NJL3W1ra6u79YpZFyorK91tQUGBu120aJG7HT58uLvNz893t1VVVe62urra3b7yyivu1szcbXd3t7vt6upytzGmTJnibkeNGuVuX375ZXd76qmnutuY+2HPnj3utqKiwt0+++yz7nb37t3u9sCBA+42K8v/OtM555zjbs866yx3W1tb627PPvtsdxuzfWhubna3MfdvzP0Qsy2J+b3FHA+MGDHC3cY8js8//3x369XW1uZup06d6m5LS0vd7cSJE93txo0b3e3DDz/sbn/wgx+423fffdfdbt682d3GHDvU1dW520wc50jShx9+6G5zc3PdbUlJibv9/ve/726feeYZd7t8+XJ3W1NT424nTZrkbvfv3+9u6+vr3W3MsVnM9j9GzHY6xvz5891te3u7u21oaHC3q1atcrczZ850t7/73e/cbcy2JOa4PuZ+GDZsmLs9HM7gAQAAAAAASDgGPAAAAAAAAAnHgAcAAAAAACDhGPAAAAAAAAAkHAMeAAAAAACAhGPAAwAAAAAAkHAMeAAAAAAAABKOAQ8AAAAAAEDCMeABAAAAAABIOAY8AAAAAAAACZc90AsA5OTkuNtrrrnG3Z500knu9uDBg+62u7vb3d5yyy3utry83N2+9NJL7nbevHnutrW11d02Nze7W6/S0lJ3u3jxYnd74403utuysjJ3+8ADD7jbd999190WFha622uvvdbdXnrppe72jjvucLf79+93t8OHD3e3MfLz891tZ2enu505c6a7bW9vd7eTJk1yt+PGjXO3e/fudbdtbW3udt++fe62sbHR3ZaUlLjbmO3el7/8ZXcbs42MeQw999xz7jZmvzJ9+nR3+9prr7nbqVOnuts33njD3cbsi2N+ttraWneblfXZv565fft2dxvzuBw9erS7rampcbc333yzu/3a177mbn/84x+726uvvtrdjh071t3GHEc2NTW52zFjxrjbGHV1de42Zr9iZu524cKFGbndoqIid3veeee52+rqandbVVXlbnNzc91tcXGxu82Us88+293u3r3b3TY0NLjbESNGuNsNGza425jj761bt7rbmOOMmH1mzHHRnDlz3O22bdvc7eFwBg8AAAAAAEDCMeABAAAAAABIOAY8AAAAAAAACceABwAAAAAAIOEY8AAAAAAAACQcAx4AAAAAAICEY8ADAAAAAACQcAx4AAAAAAAAEo4BDwAAAAAAQMIx4AEAAAAAAEi47IFeAAxOhYWF7ranp8fdzp07190WFxe725UrV7rb6dOnu9sxY8a4202bNrnbvLw8d3v66ae728bGxowsg9eMGTPc7aRJk9zttm3b3G1NTY27HT16tLvt7u52t9XV1e529erV7rapqcnd1tfXu9sY2dmZ2e3E3GfDhg1ztzG/4/fee8/dvvHGG+72wgsvdLcPP/ywu41Z18ePH+9ut2/f7m4PHjyYkWWIEbM+/Pa3v3W3MfuKmH3myJEj3e2GDRvc7ZYtW9ztaaed5m5POeUUd5ubm+tuGxoa3O2uXbvcrdeCBQvc7XPPPedus7L8r73m5+dnZBlmzpzpbp944gl3G7PfnjBhgrt9/PHH3W3MsWHM4ydGQUFBRtrm5mZ3u3HjRncbs42MWXdee+01dxtzDBVzrBPzeOvq6spIG6OlpcXdVlZWutvJkye72927d2dkGYqKitxtzO94zZo17nbixInudt68ee42Zv1dt26duz0czuABAAAAAABIOAY8AAAAAAAACceABwAAAAAAIOEY8AAAAAAAACQcAx4AAAAAAICEY8ADAAAAAACQcAx4AAAAAAAAEo4BDwAAAAAAQMIx4AEAAAAAAEg4BjwAAAAAAAAJlz3QC4DBqbGx0d22tra623PPPdfdTp482d0uXrzY3d59993utra21t329PS4246ODnfb2dnpbltaWtxtfn6+u/V655133O2uXbvc7QUXXOBuZ8+e7W4rKircbWlpqbu95JJL3O2tt97qbj/66CN3G2P48OHutrCwMCPLUFRU5G4PHjzobnfs2OFuTzzxRHe7dOlSd/voo4+62wMHDrjbhoYGd1tdXe1u9+7d627PPPNMdzty5Eh3G2P8+PHutqqqyt2Wl5e728rKSne7bt06d1tSUuJuYx4XGzdudLfDhg1ztzGP4/Xr17vbMWPGuFuvDz/80N0uWLDA3XZ1dbnblStXuttZs2a525ifbdWqVe425vdQXFzsbmN+tphjrfnz57vbGO3t7e42NzfX3cY81mJut66uzt2uXbvW3cYcc5qZu21ra3O3OTk57jY72/+0OVPHOjU1Ne527Nix7jbmd7Fnzx53u2LFCnd75513utsNGza42ylTprjbmOdMJ598sruNWd6srE9//g1n8AAAAAAAACQcAx4AAAAAAICEY8ADAAAAAACQcAx4AAAAAAAAEo4BDwAAAAAAQMIx4AEAAAAAAEg4BjwAAAAAAAAJx4AHAAAAAAAg4RjwAAAAAAAAJBwDHgAAAAAAgITLHugFwODU0dHhbvPy8txtS0uLu12/fr27/eCDD9xtVpZ/LtrU1ORuYxQXF7tbM3O3w4cPd7dtbW3u1qu1tdXd7tmzx90++eST7vb55593t9OnT3e31dXV7nbv3r3utra21t3GPC5zcnLcbWFhobvNlObmZnf77W9/291+73vfc7fl5eXudsWKFe72rbfeysgyxKwPMY/NadOmuduKigp3O2vWLHcbo6amxt1WVVW527q6Onf7wx/+0N1ef/317nbYsGHutqenx93G7IPee+89dxuzf83OHthD2JKSEne7c+fOjNzuuHHj3G1nZ6e7LSsrc7dr1qxxt5dffrm7feedd9xtzGP4nnvucbe/+tWv3G2MmN/brl273G19fb27jTk2POmkk9xtzL546tSp7nbLli3udsKECe723Xffdbcx90PM/jXGnDlz3G3Mc6Z9+/a525j74emnn3a3BQUF7nb//v3utrKy0t12dXW52w8//NDdxjxniXkMHQ5n8AAAAAAAACQcAx4AAAAAAICEY8ADAAAAAACQcAx4AAAAAAAAEo4BDwAAAAAAQMIx4AEAAAAAAEg4BjwAAAAAAAAJx4AHAAAAAAAg4RjwAAAAAAAAJBwDHgAAAAAAgITLHugFwOCUleWfHebn52fkduvq6txtXl6eu21paXG3ubm57ranp8fdmpm7bW1tdbcx9293d7e7zcS/H3N/7d+/391mZ/s3i01NTe42Zn3s6Ohwt8OHD3e3Mbq6utxtCCEjyxDjoosucrc/+tGP3G1lZaW73bNnj7sdOXKku43Z5jQ2NrrboqKijLSnnnqqu92xY4e7Xb16tbuNcdddd7nbxYsXu9vdu3e725jt6UMPPeRu29vb3W3M/mrs2LHutrS01N3G3Gcxj83Zs2e7W6+Yx1pzc7O7nTZtmruN2We+/fbb7nb+/PnudsyYMe62qqrK3cbsXwsKCtztq6++6m4ztc2Jefy0tbW525ycHHcbs+7EHBcVFxe72+3bt7vbTB3rnHHGGe42Zp0cP3780SzOJ9q8ebO73bt3r7stKytztzHr79NPP+1uY47rJ02a5G5j9is1NTXudsuWLe425rho9OjR7vZwOIMHAAAAAAAg4RjwAAAAAAAAJBwDHgAAAAAAgIRjwAMAAAAAAJBwDHgAAAAAAAASjgEPAAAAAABAwjHgAQAAAAAASDgGPAAAAAAAAAnHgAcAAAAAACDhGPAAAAAAAAAknIUQBnoZAAAAAAAA8ClwBg8AAAAAAEDCMeABAAAAAABIOAY8AAAAAAAACceABwAAAAAAIOEY8AAAAAAAACQcAx4AAAAAAICEY8ADAAAAAACQcAx4AAAAAAAAEo4BDwAAAAAAQMIx4AEAAAAAAEg4BjwAAAAAAAAJx4AHAAAAAAAg4RjwAAAAAAAAJBwDHgAAAAAAgIRjwAMAAAAAAJBwDHgAAAAAAAASjgEPAAAAAABAwjHgAQAAAAAASDgGPAAAAAAAAAnHgAcAAAAAACDhGPAAAAAAAAAkHAMeAAAAAACAhGPAAwAAAAAAkHD/H36jYmVVdVrYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1152x1080 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'shap_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\projects\\python\\Mac-Neural-Network-Project\\buid_train.ipynb Cell 29'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/python/Mac-Neural-Network-Project/buid_train.ipynb#ch0000034?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/python/Mac-Neural-Network-Project/buid_train.ipynb#ch0000034?line=6'>7</a>\u001b[0m \u001b[39m# Plot shap values\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/projects/python/Mac-Neural-Network-Project/buid_train.ipynb#ch0000034?line=7'>8</a>\u001b[0m shap\u001b[39m.\u001b[39mimage_plot(shap_values, \u001b[39m-\u001b[39mx_test_each_class)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shap_values' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot reference column\n",
    "plot_categories(images_dict)\n",
    "\n",
    "# Print an empty line to separate the two plots\n",
    "print()\n",
    "\n",
    "# Plot shap values\n",
    "shap.image_plot(shap_values, -x_test_each_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\projects\\python\\Mac-Neural-Network-Project\\buid_train.ipynb Cell 30'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/python/Mac-Neural-Network-Project/buid_train.ipynb#ch0000035?line=0'>1</a>\u001b[0m \u001b[39m# Save the probability of belonging to each class for the fifth element of the set\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/projects/python/Mac-Neural-Network-Project/buid_train.ipynb#ch0000035?line=1'>2</a>\u001b[0m coat_probs \u001b[39m=\u001b[39m predictions[\u001b[39m4\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/python/Mac-Neural-Network-Project/buid_train.ipynb#ch0000035?line=3'>4</a>\u001b[0m \u001b[39m# Order the probabilities in ascending order\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/python/Mac-Neural-Network-Project/buid_train.ipynb#ch0000035?line=4'>5</a>\u001b[0m coat_args \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(coat_probs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the probability of belonging to each class for the fifth element of the set\n",
    "coat_probs = predictions[4]\n",
    "\n",
    "# Order the probabilities in ascending order\n",
    "coat_args = np.argsort(coat_probs)\n",
    "\n",
    "# Reverse the list and get the top 3 probabilities\n",
    "top_coat_args = coat_args[::-1][:3]\n",
    "\n",
    "# Print (ordered) top 3 classes\n",
    "for i in list(top_coat_args):\n",
    "  print(class_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"graph_neuralnetwork\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(10, 9, 12)]             0         \n",
      "                                                                 \n",
      " tf.reshape (TFOpLambda)     (10, 108)                 0         \n",
      "                                                                 \n",
      " gcn (GCN)                   (10, 108)                 34992     \n",
      "                                                                 \n",
      " graph_layer1 (Activation)   (10, 108)                 0         \n",
      "                                                                 \n",
      " gcn_1 (GCN)                 (10, 108)                 34992     \n",
      "                                                                 \n",
      " graph_layer2 (Activation)   (10, 108)                 0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (10, 108)                432       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense1 (Dense)              (10, 32)                  3488      \n",
      "                                                                 \n",
      " out_layer (Dense)           (10, 7)                   231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,135\n",
      "Trainable params: 73,919\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"mode/base_model\",\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "42/42 - 4s - loss: 2.1302 - accuracy: 0.1786 - val_loss: 22.5259 - val_accuracy: 0.1429 - 4s/epoch - 91ms/step\n",
      "Epoch 2/150\n",
      "42/42 - 0s - loss: 1.9370 - accuracy: 0.2048 - val_loss: 9.5422 - val_accuracy: 0.1429 - 281ms/epoch - 7ms/step\n",
      "Epoch 3/150\n",
      "42/42 - 0s - loss: 1.8921 - accuracy: 0.1929 - val_loss: 2.1150 - val_accuracy: 0.1857 - 278ms/epoch - 7ms/step\n",
      "Epoch 4/150\n",
      "42/42 - 0s - loss: 1.8706 - accuracy: 0.2310 - val_loss: 45.8393 - val_accuracy: 0.1429 - 311ms/epoch - 7ms/step\n",
      "Epoch 5/150\n",
      "42/42 - 0s - loss: 1.7696 - accuracy: 0.2310 - val_loss: 1.9678 - val_accuracy: 0.2286 - 274ms/epoch - 7ms/step\n",
      "Epoch 6/150\n",
      "42/42 - 0s - loss: 1.7380 - accuracy: 0.2667 - val_loss: 3.0304 - val_accuracy: 0.1643 - 241ms/epoch - 6ms/step\n",
      "Epoch 7/150\n",
      "42/42 - 0s - loss: 1.7302 - accuracy: 0.2786 - val_loss: 2.9058 - val_accuracy: 0.2429 - 233ms/epoch - 6ms/step\n",
      "Epoch 8/150\n",
      "42/42 - 0s - loss: 1.7788 - accuracy: 0.2738 - val_loss: 28.0583 - val_accuracy: 0.1429 - 246ms/epoch - 6ms/step\n",
      "Epoch 9/150\n",
      "42/42 - 0s - loss: 1.8480 - accuracy: 0.2238 - val_loss: 20.6083 - val_accuracy: 0.1571 - 233ms/epoch - 6ms/step\n",
      "Epoch 10/150\n",
      "42/42 - 0s - loss: 1.9200 - accuracy: 0.1738 - val_loss: 4.1843 - val_accuracy: 0.1857 - 243ms/epoch - 6ms/step\n",
      "Epoch 11/150\n",
      "42/42 - 0s - loss: 1.8697 - accuracy: 0.2119 - val_loss: 6.6188 - val_accuracy: 0.1429 - 225ms/epoch - 5ms/step\n",
      "Epoch 12/150\n",
      "42/42 - 0s - loss: 1.8535 - accuracy: 0.2190 - val_loss: 5.7300 - val_accuracy: 0.1429 - 244ms/epoch - 6ms/step\n",
      "Epoch 13/150\n",
      "42/42 - 0s - loss: 1.8495 - accuracy: 0.2476 - val_loss: 7.5194 - val_accuracy: 0.1429 - 257ms/epoch - 6ms/step\n",
      "Epoch 14/150\n",
      "42/42 - 0s - loss: 1.8631 - accuracy: 0.2190 - val_loss: 22.5801 - val_accuracy: 0.1571 - 236ms/epoch - 6ms/step\n",
      "Epoch 15/150\n",
      "42/42 - 0s - loss: 1.7834 - accuracy: 0.2357 - val_loss: 9.4769 - val_accuracy: 0.1429 - 231ms/epoch - 6ms/step\n",
      "Epoch 16/150\n",
      "42/42 - 0s - loss: 1.7593 - accuracy: 0.2476 - val_loss: 5.4456 - val_accuracy: 0.1357 - 217ms/epoch - 5ms/step\n",
      "Epoch 17/150\n",
      "42/42 - 0s - loss: 1.7657 - accuracy: 0.2500 - val_loss: 6.8466 - val_accuracy: 0.1786 - 225ms/epoch - 5ms/step\n",
      "Epoch 18/150\n",
      "42/42 - 0s - loss: 1.7185 - accuracy: 0.2667 - val_loss: 3.4303 - val_accuracy: 0.1571 - 224ms/epoch - 5ms/step\n",
      "Epoch 19/150\n",
      "42/42 - 0s - loss: 1.7126 - accuracy: 0.2667 - val_loss: 2.3305 - val_accuracy: 0.1786 - 221ms/epoch - 5ms/step\n",
      "Epoch 20/150\n",
      "42/42 - 0s - loss: 1.6651 - accuracy: 0.3071 - val_loss: 3.8293 - val_accuracy: 0.1429 - 228ms/epoch - 5ms/step\n",
      "Epoch 21/150\n",
      "42/42 - 0s - loss: 1.6728 - accuracy: 0.2881 - val_loss: 2.5550 - val_accuracy: 0.1857 - 242ms/epoch - 6ms/step\n",
      "Epoch 22/150\n",
      "42/42 - 0s - loss: 1.7027 - accuracy: 0.2500 - val_loss: 1.9262 - val_accuracy: 0.2214 - 449ms/epoch - 11ms/step\n",
      "Epoch 23/150\n",
      "42/42 - 0s - loss: 1.6866 - accuracy: 0.3024 - val_loss: 6.0125 - val_accuracy: 0.1429 - 248ms/epoch - 6ms/step\n",
      "Epoch 24/150\n",
      "42/42 - 0s - loss: 1.7642 - accuracy: 0.2905 - val_loss: 2.7910 - val_accuracy: 0.1500 - 221ms/epoch - 5ms/step\n",
      "Epoch 25/150\n",
      "42/42 - 0s - loss: 1.6554 - accuracy: 0.3048 - val_loss: 3.6970 - val_accuracy: 0.1500 - 224ms/epoch - 5ms/step\n",
      "Epoch 26/150\n",
      "42/42 - 0s - loss: 1.6517 - accuracy: 0.3310 - val_loss: 3.8299 - val_accuracy: 0.1500 - 212ms/epoch - 5ms/step\n",
      "Epoch 27/150\n",
      "42/42 - 0s - loss: 1.6507 - accuracy: 0.3048 - val_loss: 2.2851 - val_accuracy: 0.2143 - 223ms/epoch - 5ms/step\n",
      "Epoch 28/150\n",
      "42/42 - 0s - loss: 1.6655 - accuracy: 0.3214 - val_loss: 1.9747 - val_accuracy: 0.2500 - 248ms/epoch - 6ms/step\n",
      "Epoch 29/150\n",
      "42/42 - 0s - loss: 1.6455 - accuracy: 0.3167 - val_loss: 10.4742 - val_accuracy: 0.1429 - 273ms/epoch - 6ms/step\n",
      "Epoch 30/150\n",
      "42/42 - 0s - loss: 1.6444 - accuracy: 0.3119 - val_loss: 3.4533 - val_accuracy: 0.1500 - 228ms/epoch - 5ms/step\n",
      "Epoch 31/150\n",
      "42/42 - 0s - loss: 1.6274 - accuracy: 0.2952 - val_loss: 6.9517 - val_accuracy: 0.1429 - 224ms/epoch - 5ms/step\n",
      "Epoch 32/150\n",
      "42/42 - 0s - loss: 1.6914 - accuracy: 0.2976 - val_loss: 2.9555 - val_accuracy: 0.2000 - 217ms/epoch - 5ms/step\n",
      "Epoch 33/150\n",
      "42/42 - 0s - loss: 1.6448 - accuracy: 0.2905 - val_loss: 4.4119 - val_accuracy: 0.1286 - 219ms/epoch - 5ms/step\n",
      "Epoch 34/150\n",
      "42/42 - 0s - loss: 1.6570 - accuracy: 0.3190 - val_loss: 6.6059 - val_accuracy: 0.1500 - 249ms/epoch - 6ms/step\n",
      "Epoch 35/150\n",
      "42/42 - 0s - loss: 1.6437 - accuracy: 0.3190 - val_loss: 1.8523 - val_accuracy: 0.2286 - 219ms/epoch - 5ms/step\n",
      "Epoch 36/150\n",
      "42/42 - 0s - loss: 1.5979 - accuracy: 0.3810 - val_loss: 1.9826 - val_accuracy: 0.1929 - 236ms/epoch - 6ms/step\n",
      "Epoch 37/150\n",
      "42/42 - 0s - loss: 1.5785 - accuracy: 0.3548 - val_loss: 2.7531 - val_accuracy: 0.1857 - 242ms/epoch - 6ms/step\n",
      "Epoch 38/150\n",
      "42/42 - 0s - loss: 1.6335 - accuracy: 0.3500 - val_loss: 9.4207 - val_accuracy: 0.1571 - 234ms/epoch - 6ms/step\n",
      "Epoch 39/150\n",
      "42/42 - 0s - loss: 1.6543 - accuracy: 0.3143 - val_loss: 3.0992 - val_accuracy: 0.1929 - 228ms/epoch - 5ms/step\n",
      "Epoch 40/150\n",
      "42/42 - 0s - loss: 1.5675 - accuracy: 0.3524 - val_loss: 2.8369 - val_accuracy: 0.1643 - 224ms/epoch - 5ms/step\n",
      "Epoch 41/150\n",
      "42/42 - 0s - loss: 1.6073 - accuracy: 0.3548 - val_loss: 1.9675 - val_accuracy: 0.2500 - 228ms/epoch - 5ms/step\n",
      "Epoch 42/150\n",
      "42/42 - 0s - loss: 1.5888 - accuracy: 0.3214 - val_loss: 7.8860 - val_accuracy: 0.1357 - 218ms/epoch - 5ms/step\n",
      "Epoch 43/150\n",
      "42/42 - 0s - loss: 1.6396 - accuracy: 0.3476 - val_loss: 10.0372 - val_accuracy: 0.1429 - 250ms/epoch - 6ms/step\n",
      "Epoch 44/150\n",
      "42/42 - 0s - loss: 1.6074 - accuracy: 0.3381 - val_loss: 3.8382 - val_accuracy: 0.1429 - 262ms/epoch - 6ms/step\n",
      "Epoch 45/150\n",
      "42/42 - 0s - loss: 1.6388 - accuracy: 0.3190 - val_loss: 3.0234 - val_accuracy: 0.1929 - 248ms/epoch - 6ms/step\n",
      "Epoch 46/150\n",
      "42/42 - 0s - loss: 1.5864 - accuracy: 0.3310 - val_loss: 2.1834 - val_accuracy: 0.2000 - 226ms/epoch - 5ms/step\n",
      "Epoch 47/150\n",
      "42/42 - 0s - loss: 1.5794 - accuracy: 0.3500 - val_loss: 5.7340 - val_accuracy: 0.1714 - 255ms/epoch - 6ms/step\n",
      "Epoch 48/150\n",
      "42/42 - 0s - loss: 1.5791 - accuracy: 0.3810 - val_loss: 5.6519 - val_accuracy: 0.1857 - 223ms/epoch - 5ms/step\n",
      "Epoch 49/150\n",
      "42/42 - 0s - loss: 1.6074 - accuracy: 0.3452 - val_loss: 2.4599 - val_accuracy: 0.2143 - 225ms/epoch - 5ms/step\n",
      "Epoch 50/150\n",
      "42/42 - 0s - loss: 1.5166 - accuracy: 0.3738 - val_loss: 2.4165 - val_accuracy: 0.1929 - 231ms/epoch - 5ms/step\n",
      "Epoch 51/150\n",
      "42/42 - 0s - loss: 1.6137 - accuracy: 0.3548 - val_loss: 6.7627 - val_accuracy: 0.1571 - 221ms/epoch - 5ms/step\n",
      "Epoch 52/150\n",
      "42/42 - 0s - loss: 1.5937 - accuracy: 0.3476 - val_loss: 5.1929 - val_accuracy: 0.2000 - 224ms/epoch - 5ms/step\n",
      "Epoch 53/150\n",
      "42/42 - 0s - loss: 1.6003 - accuracy: 0.3571 - val_loss: 2.1484 - val_accuracy: 0.2214 - 223ms/epoch - 5ms/step\n",
      "Epoch 54/150\n",
      "42/42 - 0s - loss: 1.5991 - accuracy: 0.3310 - val_loss: 1.9396 - val_accuracy: 0.2571 - 215ms/epoch - 5ms/step\n",
      "Epoch 55/150\n",
      "42/42 - 0s - loss: 1.5313 - accuracy: 0.3714 - val_loss: 5.2369 - val_accuracy: 0.1429 - 232ms/epoch - 6ms/step\n",
      "Epoch 56/150\n",
      "42/42 - 0s - loss: 1.5984 - accuracy: 0.3500 - val_loss: 2.0816 - val_accuracy: 0.2214 - 223ms/epoch - 5ms/step\n",
      "Epoch 57/150\n",
      "42/42 - 0s - loss: 1.5430 - accuracy: 0.3595 - val_loss: 4.4978 - val_accuracy: 0.2143 - 214ms/epoch - 5ms/step\n",
      "Epoch 58/150\n",
      "42/42 - 0s - loss: 1.5588 - accuracy: 0.3548 - val_loss: 4.4878 - val_accuracy: 0.2000 - 229ms/epoch - 5ms/step\n",
      "Epoch 59/150\n",
      "42/42 - 0s - loss: 1.5979 - accuracy: 0.3714 - val_loss: 7.6631 - val_accuracy: 0.1571 - 231ms/epoch - 5ms/step\n",
      "Epoch 60/150\n",
      "42/42 - 0s - loss: 1.5007 - accuracy: 0.3976 - val_loss: 3.7060 - val_accuracy: 0.1857 - 233ms/epoch - 6ms/step\n",
      "Epoch 61/150\n",
      "42/42 - 0s - loss: 1.5202 - accuracy: 0.3714 - val_loss: 2.7618 - val_accuracy: 0.2357 - 245ms/epoch - 6ms/step\n",
      "Epoch 62/150\n",
      "42/42 - 0s - loss: 1.5586 - accuracy: 0.3619 - val_loss: 2.1376 - val_accuracy: 0.2143 - 250ms/epoch - 6ms/step\n",
      "Epoch 63/150\n",
      "42/42 - 0s - loss: 1.4712 - accuracy: 0.4310 - val_loss: 4.7532 - val_accuracy: 0.1929 - 264ms/epoch - 6ms/step\n",
      "Epoch 64/150\n",
      "42/42 - 0s - loss: 1.4961 - accuracy: 0.3595 - val_loss: 1.9307 - val_accuracy: 0.2714 - 223ms/epoch - 5ms/step\n",
      "Epoch 65/150\n",
      "42/42 - 0s - loss: 1.5117 - accuracy: 0.3905 - val_loss: 2.3975 - val_accuracy: 0.1786 - 239ms/epoch - 6ms/step\n",
      "Epoch 66/150\n",
      "42/42 - 0s - loss: 1.4934 - accuracy: 0.3976 - val_loss: 9.9808 - val_accuracy: 0.1500 - 225ms/epoch - 5ms/step\n",
      "Epoch 67/150\n",
      "42/42 - 0s - loss: 1.5412 - accuracy: 0.3595 - val_loss: 5.8942 - val_accuracy: 0.1643 - 222ms/epoch - 5ms/step\n",
      "Epoch 68/150\n",
      "42/42 - 0s - loss: 1.5432 - accuracy: 0.3714 - val_loss: 8.9201 - val_accuracy: 0.1429 - 226ms/epoch - 5ms/step\n",
      "Epoch 69/150\n",
      "42/42 - 0s - loss: 1.5463 - accuracy: 0.4024 - val_loss: 3.4528 - val_accuracy: 0.1714 - 254ms/epoch - 6ms/step\n",
      "Epoch 70/150\n",
      "42/42 - 0s - loss: 1.4743 - accuracy: 0.3643 - val_loss: 7.7773 - val_accuracy: 0.1357 - 262ms/epoch - 6ms/step\n",
      "Epoch 71/150\n",
      "42/42 - 0s - loss: 1.4906 - accuracy: 0.4000 - val_loss: 2.2118 - val_accuracy: 0.2357 - 248ms/epoch - 6ms/step\n",
      "Epoch 72/150\n",
      "42/42 - 0s - loss: 1.5579 - accuracy: 0.3476 - val_loss: 2.2405 - val_accuracy: 0.2214 - 238ms/epoch - 6ms/step\n",
      "Epoch 73/150\n",
      "42/42 - 0s - loss: 1.5214 - accuracy: 0.4333 - val_loss: 3.7312 - val_accuracy: 0.1429 - 232ms/epoch - 6ms/step\n",
      "Epoch 74/150\n",
      "42/42 - 0s - loss: 1.4956 - accuracy: 0.3905 - val_loss: 3.3337 - val_accuracy: 0.1929 - 246ms/epoch - 6ms/step\n",
      "Epoch 75/150\n",
      "42/42 - 0s - loss: 1.4944 - accuracy: 0.4000 - val_loss: 2.1858 - val_accuracy: 0.2357 - 295ms/epoch - 7ms/step\n",
      "Epoch 76/150\n",
      "42/42 - 0s - loss: 1.4808 - accuracy: 0.4000 - val_loss: 6.1505 - val_accuracy: 0.1500 - 243ms/epoch - 6ms/step\n",
      "Epoch 77/150\n",
      "42/42 - 1s - loss: 1.5224 - accuracy: 0.4167 - val_loss: 4.1701 - val_accuracy: 0.1286 - 823ms/epoch - 20ms/step\n",
      "Epoch 78/150\n",
      "42/42 - 0s - loss: 1.4602 - accuracy: 0.4262 - val_loss: 4.3941 - val_accuracy: 0.1071 - 275ms/epoch - 7ms/step\n",
      "Epoch 79/150\n",
      "42/42 - 0s - loss: 1.5080 - accuracy: 0.3881 - val_loss: 2.7194 - val_accuracy: 0.2214 - 227ms/epoch - 5ms/step\n",
      "Epoch 80/150\n",
      "42/42 - 0s - loss: 1.5092 - accuracy: 0.3452 - val_loss: 2.0305 - val_accuracy: 0.2786 - 248ms/epoch - 6ms/step\n",
      "Epoch 81/150\n",
      "42/42 - 0s - loss: 1.4918 - accuracy: 0.4024 - val_loss: 4.1776 - val_accuracy: 0.1500 - 236ms/epoch - 6ms/step\n",
      "Epoch 82/150\n",
      "42/42 - 0s - loss: 1.4972 - accuracy: 0.3952 - val_loss: 4.9479 - val_accuracy: 0.1571 - 239ms/epoch - 6ms/step\n",
      "Epoch 83/150\n",
      "42/42 - 0s - loss: 1.4959 - accuracy: 0.3952 - val_loss: 8432.9980 - val_accuracy: 0.1429 - 224ms/epoch - 5ms/step\n",
      "Epoch 84/150\n",
      "42/42 - 1s - loss: 1.4679 - accuracy: 0.3952 - val_loss: 2.2463 - val_accuracy: 0.2357 - 564ms/epoch - 13ms/step\n",
      "Epoch 85/150\n",
      "42/42 - 1s - loss: 1.4925 - accuracy: 0.3786 - val_loss: 17.1014 - val_accuracy: 0.1500 - 517ms/epoch - 12ms/step\n",
      "Epoch 86/150\n",
      "42/42 - 0s - loss: 1.5079 - accuracy: 0.3714 - val_loss: 12.0886 - val_accuracy: 0.1286 - 325ms/epoch - 8ms/step\n",
      "Epoch 87/150\n",
      "42/42 - 0s - loss: 1.6094 - accuracy: 0.3643 - val_loss: 14.8686 - val_accuracy: 0.1429 - 484ms/epoch - 12ms/step\n",
      "Epoch 88/150\n",
      "42/42 - 0s - loss: 1.5555 - accuracy: 0.3262 - val_loss: 4.2539 - val_accuracy: 0.1429 - 195ms/epoch - 5ms/step\n",
      "Epoch 89/150\n",
      "42/42 - 0s - loss: 1.5027 - accuracy: 0.3905 - val_loss: 3.7752 - val_accuracy: 0.1714 - 192ms/epoch - 5ms/step\n",
      "Epoch 90/150\n",
      "42/42 - 0s - loss: 1.4858 - accuracy: 0.4119 - val_loss: 3.3982 - val_accuracy: 0.1500 - 187ms/epoch - 4ms/step\n",
      "Epoch 91/150\n",
      "42/42 - 0s - loss: 1.5374 - accuracy: 0.3786 - val_loss: 2.1099 - val_accuracy: 0.2929 - 198ms/epoch - 5ms/step\n",
      "Epoch 92/150\n",
      "42/42 - 0s - loss: 1.4537 - accuracy: 0.4214 - val_loss: 2.1131 - val_accuracy: 0.2714 - 201ms/epoch - 5ms/step\n",
      "Epoch 93/150\n",
      "42/42 - 0s - loss: 1.4637 - accuracy: 0.4333 - val_loss: 14.8841 - val_accuracy: 0.1429 - 265ms/epoch - 6ms/step\n",
      "Epoch 94/150\n",
      "42/42 - 0s - loss: 1.6493 - accuracy: 0.3190 - val_loss: 5.1987 - val_accuracy: 0.1786 - 186ms/epoch - 4ms/step\n",
      "Epoch 95/150\n",
      "42/42 - 0s - loss: 1.6080 - accuracy: 0.2952 - val_loss: 6.2978 - val_accuracy: 0.1786 - 235ms/epoch - 6ms/step\n",
      "Epoch 96/150\n",
      "42/42 - 0s - loss: 1.6178 - accuracy: 0.3595 - val_loss: 5.1286 - val_accuracy: 0.1429 - 193ms/epoch - 5ms/step\n",
      "Epoch 97/150\n",
      "42/42 - 1s - loss: 1.6351 - accuracy: 0.3143 - val_loss: 5.4156 - val_accuracy: 0.1500 - 583ms/epoch - 14ms/step\n",
      "Epoch 98/150\n",
      "42/42 - 0s - loss: 1.6699 - accuracy: 0.2643 - val_loss: 10.4456 - val_accuracy: 0.1357 - 271ms/epoch - 6ms/step\n",
      "Epoch 99/150\n",
      "42/42 - 0s - loss: 1.6107 - accuracy: 0.3262 - val_loss: 2.5641 - val_accuracy: 0.2071 - 299ms/epoch - 7ms/step\n",
      "Epoch 100/150\n",
      "42/42 - 0s - loss: 1.5071 - accuracy: 0.4095 - val_loss: 9.7917 - val_accuracy: 0.1643 - 260ms/epoch - 6ms/step\n",
      "Epoch 101/150\n",
      "42/42 - 0s - loss: 1.5865 - accuracy: 0.3286 - val_loss: 5.3037 - val_accuracy: 0.1714 - 285ms/epoch - 7ms/step\n",
      "Epoch 102/150\n",
      "42/42 - 0s - loss: 1.5609 - accuracy: 0.3405 - val_loss: 4.2889 - val_accuracy: 0.1286 - 302ms/epoch - 7ms/step\n",
      "Epoch 103/150\n",
      "42/42 - 0s - loss: 1.5961 - accuracy: 0.3333 - val_loss: 7.2439 - val_accuracy: 0.1643 - 302ms/epoch - 7ms/step\n",
      "Epoch 104/150\n",
      "42/42 - 0s - loss: 1.6810 - accuracy: 0.2429 - val_loss: 4.2575 - val_accuracy: 0.1571 - 307ms/epoch - 7ms/step\n",
      "Epoch 105/150\n",
      "42/42 - 0s - loss: 1.6326 - accuracy: 0.2976 - val_loss: 5.8064 - val_accuracy: 0.1429 - 263ms/epoch - 6ms/step\n",
      "Epoch 106/150\n",
      "42/42 - 0s - loss: 1.6020 - accuracy: 0.3000 - val_loss: 3.4653 - val_accuracy: 0.1643 - 281ms/epoch - 7ms/step\n",
      "Epoch 107/150\n",
      "42/42 - 0s - loss: 1.6243 - accuracy: 0.2762 - val_loss: 3.5953 - val_accuracy: 0.1286 - 269ms/epoch - 6ms/step\n",
      "Epoch 108/150\n",
      "42/42 - 0s - loss: 1.6912 - accuracy: 0.2524 - val_loss: 4.9996 - val_accuracy: 0.1357 - 246ms/epoch - 6ms/step\n",
      "Epoch 109/150\n",
      "42/42 - 0s - loss: 1.6596 - accuracy: 0.2524 - val_loss: 2.4333 - val_accuracy: 0.1500 - 303ms/epoch - 7ms/step\n",
      "Epoch 110/150\n",
      "42/42 - 0s - loss: 1.6242 - accuracy: 0.2810 - val_loss: 2.7125 - val_accuracy: 0.1357 - 267ms/epoch - 6ms/step\n",
      "Epoch 111/150\n",
      "42/42 - 0s - loss: 1.6462 - accuracy: 0.3024 - val_loss: 3.8308 - val_accuracy: 0.1214 - 264ms/epoch - 6ms/step\n",
      "Epoch 112/150\n",
      "42/42 - 0s - loss: 1.6526 - accuracy: 0.2429 - val_loss: 3.5259 - val_accuracy: 0.1500 - 293ms/epoch - 7ms/step\n",
      "Epoch 113/150\n",
      "42/42 - 0s - loss: 1.6067 - accuracy: 0.2929 - val_loss: 2.0445 - val_accuracy: 0.2500 - 302ms/epoch - 7ms/step\n",
      "Epoch 114/150\n",
      "42/42 - 0s - loss: 1.5995 - accuracy: 0.3071 - val_loss: 3.7100 - val_accuracy: 0.1357 - 301ms/epoch - 7ms/step\n",
      "Epoch 115/150\n",
      "42/42 - 0s - loss: 1.6140 - accuracy: 0.2905 - val_loss: 1.9188 - val_accuracy: 0.2429 - 379ms/epoch - 9ms/step\n",
      "Epoch 116/150\n",
      "42/42 - 0s - loss: 1.6688 - accuracy: 0.2714 - val_loss: 1.9431 - val_accuracy: 0.2000 - 271ms/epoch - 6ms/step\n",
      "Epoch 117/150\n",
      "42/42 - 0s - loss: 1.6923 - accuracy: 0.2667 - val_loss: 2.9506 - val_accuracy: 0.1929 - 296ms/epoch - 7ms/step\n",
      "Epoch 118/150\n",
      "42/42 - 0s - loss: 1.6729 - accuracy: 0.2405 - val_loss: 2.3895 - val_accuracy: 0.1571 - 316ms/epoch - 8ms/step\n",
      "Epoch 119/150\n",
      "42/42 - 0s - loss: 1.6443 - accuracy: 0.2643 - val_loss: 1.8596 - val_accuracy: 0.2857 - 344ms/epoch - 8ms/step\n",
      "Epoch 120/150\n",
      "42/42 - 1s - loss: 1.6079 - accuracy: 0.2952 - val_loss: 2.1280 - val_accuracy: 0.1500 - 501ms/epoch - 12ms/step\n",
      "Epoch 121/150\n",
      "42/42 - 0s - loss: 1.6162 - accuracy: 0.3286 - val_loss: 2.2568 - val_accuracy: 0.1429 - 320ms/epoch - 8ms/step\n",
      "Epoch 122/150\n",
      "42/42 - 0s - loss: 1.6394 - accuracy: 0.2476 - val_loss: 2.1010 - val_accuracy: 0.1571 - 292ms/epoch - 7ms/step\n",
      "Epoch 123/150\n",
      "42/42 - 0s - loss: 1.6013 - accuracy: 0.2833 - val_loss: 1.9048 - val_accuracy: 0.2571 - 315ms/epoch - 8ms/step\n",
      "Epoch 124/150\n",
      "42/42 - 0s - loss: 1.6231 - accuracy: 0.2738 - val_loss: 2.1573 - val_accuracy: 0.1714 - 308ms/epoch - 7ms/step\n",
      "Epoch 125/150\n",
      "42/42 - 0s - loss: 1.6212 - accuracy: 0.2833 - val_loss: 1.8849 - val_accuracy: 0.2286 - 463ms/epoch - 11ms/step\n",
      "Epoch 126/150\n",
      "42/42 - 0s - loss: 1.6198 - accuracy: 0.2690 - val_loss: 5.8143 - val_accuracy: 0.1286 - 415ms/epoch - 10ms/step\n",
      "Epoch 127/150\n",
      "42/42 - 1s - loss: 1.6630 - accuracy: 0.2667 - val_loss: 1.9551 - val_accuracy: 0.2071 - 526ms/epoch - 13ms/step\n",
      "Epoch 128/150\n",
      "42/42 - 0s - loss: 1.6071 - accuracy: 0.2810 - val_loss: 1.9075 - val_accuracy: 0.2929 - 451ms/epoch - 11ms/step\n",
      "Epoch 129/150\n",
      "42/42 - 0s - loss: 1.6164 - accuracy: 0.3024 - val_loss: 2.1857 - val_accuracy: 0.1786 - 323ms/epoch - 8ms/step\n",
      "Epoch 130/150\n",
      "42/42 - 0s - loss: 1.5910 - accuracy: 0.2857 - val_loss: 1.9643 - val_accuracy: 0.1714 - 381ms/epoch - 9ms/step\n",
      "Epoch 131/150\n",
      "42/42 - 0s - loss: 1.6049 - accuracy: 0.3024 - val_loss: 2.0858 - val_accuracy: 0.2214 - 274ms/epoch - 7ms/step\n",
      "Epoch 132/150\n",
      "42/42 - 0s - loss: 1.6523 - accuracy: 0.2786 - val_loss: 2.0501 - val_accuracy: 0.1857 - 267ms/epoch - 6ms/step\n",
      "Epoch 133/150\n",
      "42/42 - 0s - loss: 1.6240 - accuracy: 0.3190 - val_loss: 3.3420 - val_accuracy: 0.1571 - 281ms/epoch - 7ms/step\n",
      "Epoch 134/150\n",
      "42/42 - 0s - loss: 1.6138 - accuracy: 0.2690 - val_loss: 1.9925 - val_accuracy: 0.2286 - 313ms/epoch - 7ms/step\n",
      "Epoch 135/150\n",
      "42/42 - 0s - loss: 1.6338 - accuracy: 0.2952 - val_loss: 3.5225 - val_accuracy: 0.1571 - 314ms/epoch - 7ms/step\n",
      "Epoch 136/150\n",
      "42/42 - 0s - loss: 1.6276 - accuracy: 0.2595 - val_loss: 3.5116 - val_accuracy: 0.1571 - 319ms/epoch - 8ms/step\n",
      "Epoch 137/150\n",
      "42/42 - 0s - loss: 1.5760 - accuracy: 0.2786 - val_loss: 2.3482 - val_accuracy: 0.1500 - 291ms/epoch - 7ms/step\n",
      "Epoch 138/150\n",
      "42/42 - 0s - loss: 1.6024 - accuracy: 0.2857 - val_loss: 2.0028 - val_accuracy: 0.2786 - 255ms/epoch - 6ms/step\n",
      "Epoch 139/150\n",
      "42/42 - 0s - loss: 1.6254 - accuracy: 0.2881 - val_loss: 2.0462 - val_accuracy: 0.2286 - 294ms/epoch - 7ms/step\n",
      "Epoch 140/150\n",
      "42/42 - 0s - loss: 1.6350 - accuracy: 0.2714 - val_loss: 2.1887 - val_accuracy: 0.2071 - 284ms/epoch - 7ms/step\n",
      "Epoch 141/150\n",
      "42/42 - 0s - loss: 1.6122 - accuracy: 0.3143 - val_loss: 2.0715 - val_accuracy: 0.2143 - 322ms/epoch - 8ms/step\n",
      "Epoch 142/150\n",
      "42/42 - 0s - loss: 1.5826 - accuracy: 0.3190 - val_loss: 5.7914 - val_accuracy: 0.1071 - 275ms/epoch - 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/22 16:00:23 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Run with id=04a6b8d55e974438b2f8efed5a570fe7 not found\n"
     ]
    }
   ],
   "source": [
    "# with mlflow.start_run(nested=true):\n",
    "history = model.fit(x1,y1, batch_size=bs, epochs=epochs, callbacks=[callback],validation_data=(x2,y2),verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "<class 'keras.callbacks.History'> is not currently a supported model type!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\projects\\python\\Mac-Neural-Network-Project\\buid_train.ipynb Cell 27'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/python/Mac-Neural-Network-Project/buid_train.ipynb#ch0000027?line=1'>2</a>\u001b[0m background \u001b[39m=\u001b[39m x1[np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(x1\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m420\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/python/Mac-Neural-Network-Project/buid_train.ipynb#ch0000027?line=3'>4</a>\u001b[0m \u001b[39m# Use DeepExplainer to explain predictions of the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/projects/python/Mac-Neural-Network-Project/buid_train.ipynb#ch0000027?line=4'>5</a>\u001b[0m e \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39;49mDeepExplainer(history, background)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:84\u001b[0m, in \u001b[0;36mDeep.__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m     81\u001b[0m         framework \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     83\u001b[0m \u001b[39mif\u001b[39;00m framework \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplainer \u001b[39m=\u001b[39m TFDeep(model, data, session, learning_phase_flags)\n\u001b[0;32m     85\u001b[0m \u001b[39melif\u001b[39;00m framework \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpytorch\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     86\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplainer \u001b[39m=\u001b[39m PyTorchDeep(model, data)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:103\u001b[0m, in \u001b[0;36mTFDeep.__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m    100\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mYour TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    102\u001b[0m \u001b[39m# determine the model inputs and outputs\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_inputs \u001b[39m=\u001b[39m _get_model_inputs(model)\n\u001b[0;32m    104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output \u001b[39m=\u001b[39m _get_model_output(model)\n\u001b[0;32m    105\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mThe model output to be explained must be a single tensor!\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\tf_utils.py:68\u001b[0m, in \u001b[0;36m_get_model_inputs\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m model[\u001b[39m0\u001b[39m]\n\u001b[0;32m     67\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 68\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(model)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m is not currently a supported model type!\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: <class 'keras.callbacks.History'> is not currently a supported model type!"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.functional.Functional"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58837b1b657ea91009af8409fc244ae3b5ccf93ea980d6fb6b80adc5f697f4cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
