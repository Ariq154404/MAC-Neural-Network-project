{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import os\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(\"numpy==\"+np.__version__)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(\"tensorflow==\"+tf.__version__)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(\"pandas==\"+pd.__version__)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(\"mlflow==\"+mlflow.__version__)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(mt\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "# print(\"numpy==\"+np.__version__)\n",
    "# print(\"tensorflow==\"+tf.__version__)\n",
    "# print(\"pandas==\"+pd.__version__)\n",
    "# print(\"mlflow==\"+mlflow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64\n",
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/29 20:54:29 INFO mlflow.tracking.fluent: Experiment with name 'graph-neural-network-full' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/11', experiment_id='11', lifecycle_stage='active', name='graph-neural-network-full', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"graph-neural-network-full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def adjm(h,w,near):\n",
    "#   am=[[0 for i in range(w*h)] for j in range(h*w)]\n",
    "#   img=[[0 for i in range(w)] for j in range(h)]\n",
    "  \n",
    "#   dr=[[1,0],[0,1],[1,1],[-1,-1],[-1,0],[0,-1],[-1,1],[1,-1]]\n",
    "\n",
    "#   for i,v in enumerate(img):\n",
    "#     for j,v2 in enumerate(img[i]):\n",
    "#       timg=[[0 for i in range(w)] for j in range(h)]\n",
    "#       for k in range(0,near+1):\n",
    "#         for d in dr:\n",
    "#           posy=i+d[0]*k\n",
    "#           posx=j+d[1]*k\n",
    "#           if posy>=0 and posy<h and posx>=0 and posx<w:\n",
    "#             timg[posy][posx]=1\n",
    "#             am[i*w+j][posy*w+posx]=1\n",
    "#         print(timg)  \n",
    "\n",
    "#   return am\n",
    "\n",
    "# val=adjm(4,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train/x_train.pkl','rb') as f:\n",
    "        x1=pickle.load(f)\n",
    "with open('data/train/y_train.pkl','rb') as f:\n",
    "        y1=pickle.load( f)\n",
    "with open('data/valid/x_valid.pkl','rb') as f:\n",
    "        x2=pickle.load(f)\n",
    "with open('data/valid/y_valid.pkl','rb') as f:\n",
    "        y2=pickle.load( f)\n",
    "# with open('data/test/x_test.pkl','rb') as f:\n",
    "#         x3=pickle.load(f)\n",
    "# with open('data/test/y_test.pkl','rb') as f:\n",
    "#         y3=pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test/x_test.pkl','rb') as f:\n",
    "        x3=pickle.load(f)\n",
    "with open('data/test/y_test.pkl','rb') as f:\n",
    "        y3=pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx1\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x1' is not defined"
     ]
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "print(max(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(tf.keras.layers.Layer):\n",
    "    def __init__(self,inp_shape=9*12,out_shape=9*12,h=9, w=12,near=3):\n",
    "        super(GCN, self).__init__()\n",
    "        self.am=[[0 for i in range(w*h)] for j in range(h*w)]\n",
    "        self.img=[[0 for i in range(w)] for j in range(h)]\n",
    "  \n",
    "        self.dr=[[1,0],[0,1],[1,1],[-1,-1],[-1,0],[0,-1],[-1,1],[1,-1]]\n",
    "\n",
    "        for i,v in enumerate(self.img):\n",
    "           for j,v2 in enumerate(self.img[i]):\n",
    "        # timg=[[0 for i in range(w)] for j in range(h)]\n",
    "              for k in range(0,near+1):\n",
    "                for d in self.dr:\n",
    "                  posy=i+d[0]*k\n",
    "                  posx=j+d[1]*k\n",
    "                  if posy>=0 and posy<h and posx>=0 and posx<w:\n",
    "            # timg[posy][posx]=1\n",
    "                    self.am[i*w+j][posy*w+posx]=1\n",
    "        # print(timg) \n",
    "        self.am=np.array(self.am) \n",
    "        self.D = np.diag(np.sum(self.am, axis=0)) \n",
    "        self.Dinv=np.linalg.inv(self.D)\n",
    "        self.am=tf.Variable(self.am,trainable=True,dtype=tf.float32,name=\"ajm\")\n",
    "        self.Dinv=tf.Variable(self.Dinv,trainable=True,dtype=tf.float32,name=\"dm\")\n",
    "        # self.norm=tf.matmul(self.Dinv*self.am)\n",
    "        self.w = self.add_weight(\n",
    "            shape=(inp_shape, out_shape), initializer=\"random_normal\", trainable=True,dtype=tf.float32,name='adjw'\n",
    "        )\n",
    "        # self.b = self.add_weight(shape=(units,), initializer=\"zeros\", trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        inputs=tf.cast(inputs,dtype=tf.float32)\n",
    "        # inputs=tf.transpose()\n",
    "        # print(inputs.shape)\n",
    "        # print(\"inpshape\",tf.transpose(inputs,perm=[1,0]).shape)\n",
    "        # print(self.Dinv.shape)\n",
    "        # print(self.am.shape)\n",
    "        # print(self.w.shape)\n",
    "        first_half=tf.matmul(inputs,tf.matmul(self.Dinv,self.am))\n",
    "    \n",
    "        return tf.matmul(first_half, self.w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(near=3,lay=2,bs=bs,n_out=7):\n",
    "    \n",
    "\n",
    "    inputs = tf.keras.Input( shape=(9,12,3))\n",
    "    input=tf.transpose(inputs,perm=[3,0,1,2])\n",
    "    mlflow.log_param(\"layers\", lay)\n",
    "    mlflow.log_param(\"nearest\", near)\n",
    "    mlflow.set_tag(\"layer\", \"changed\")\n",
    "    r=input[0][:][:][:]\n",
    "    g=input[1][:][:][:]\n",
    "    b=input[2][:][:][:]\n",
    "    # print(\"red\",r.shape)\n",
    "    r=tf.keras.layers.Flatten()(r)\n",
    "    g=tf.keras.layers.Flatten()(g)\n",
    "    b=tf.keras.layers.Flatten()(b)\n",
    "    # print(inputs.shape)\n",
    "   \n",
    "    # x=tf.reshape(inputs,[inputs.shape[1]*inputs.shape[2]],name=\"initial reshape\")\n",
    "    # x=tf.keras.layers.Flatten()(inputs)\n",
    "    for i in range(lay):\n",
    "        r=GCN(near=near)(r)\n",
    "        r=tf.keras.layers.Activation('relu',name=\"graph_layerr\"+str(i+1))(r)\n",
    "    r=tf.keras.layers.BatchNormalization()(r)\n",
    "    for i in range(lay):\n",
    "        g=GCN(near=near)(g)\n",
    "        g=tf.keras.layers.Activation('relu',name=\"graph_layerg\"+str(i+1))(g)\n",
    "    g=tf.keras.layers.BatchNormalization()(g)\n",
    "    \n",
    "    for i in range(lay):\n",
    "        b=GCN(near=near)(b)\n",
    "        b=tf.keras.layers.Activation('relu',name=\"graph_layerb\"+str(i+1))(b)\n",
    "    b=tf.keras.layers.BatchNormalization()(b)\n",
    "    x=tf.stack([r,g,b])\n",
    "    x=tf.transpose(x,perm=[1,2,0])\n",
    "    # print(\"x_shape_b\",x.shape)\n",
    "    x=tf.keras.layers.Dense(units=1,activation=\"relu\",name=\"denseshrink\")(x)\n",
    "    # print(\"x_shape_a\",x.shape)\n",
    "    x=tf.squeeze(x,axis=-1)\n",
    "    # print(\"x_shape\",x.shape)\n",
    "    x=tf.keras.layers.Dense(units=32,activation=\"relu\",name=\"dense1\")(x)\n",
    "    output=tf.keras.layers.Dense(n_out,activation=\"softmax\",name=\"out_layer\")(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output, name=\"graph_neuralnetwork\")\n",
    "\n",
    "    model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"],run_eagerly=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 108)\n",
      "(None, 108)\n",
      "(None, 108)\n",
      "(None, 108)\n",
      "(None, 108)\n",
      "(None, 108)\n"
     ]
    }
   ],
   "source": [
    "model=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 20:56:25.923479: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-29 20:56:25.923956: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model(\"model/hyperparam/gcn-hyp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"graph_neuralnetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 45, 60, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TFOpLa  (3, None, 45, 60)   0           ['input_1[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 45, 60)      0           ['tf.compat.v1.transpose[0][0]'] \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 45, 60)      0           ['tf.compat.v1.transpose[0][0]'] \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8 (Sl  (None, 45, 60)      0           ['tf.compat.v1.transpose[0][0]'] \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 45, 60)      0           ['tf.__operators__.getitem[0][0]'\n",
      " icingOpLambda)                                                  ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  (None, 45, 60)      0           ['tf.__operators__.getitem_4[0][0\n",
      " icingOpLambda)                                                  ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_9 (Sl  (None, 45, 60)      0           ['tf.__operators__.getitem_8[0][0\n",
      " icingOpLambda)                                                  ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 45, 60)      0           ['tf.__operators__.getitem_1[0][0\n",
      " icingOpLambda)                                                  ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  (None, 45, 60)      0           ['tf.__operators__.getitem_5[0][0\n",
      " icingOpLambda)                                                  ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_10 (S  (None, 45, 60)      0           ['tf.__operators__.getitem_9[0][0\n",
      " licingOpLambda)                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 45, 60)      0           ['tf.__operators__.getitem_2[0][0\n",
      " icingOpLambda)                                                  ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7 (Sl  (None, 45, 60)      0           ['tf.__operators__.getitem_6[0][0\n",
      " icingOpLambda)                                                  ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_11 (S  (None, 45, 60)      0           ['tf.__operators__.getitem_10[0][\n",
      " licingOpLambda)                                                 0]']                             \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2700)         0           ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 2700)         0           ['tf.__operators__.getitem_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 2700)         0           ['tf.__operators__.getitem_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " gcn (GCN)                      (None, 2700)         21870000    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " gcn_6 (GCN)                    (None, 2700)         21870000    ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " gcn_12 (GCN)                   (None, 2700)         21870000    ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " graph_layerr1 (Activation)     (None, 2700)         0           ['gcn[0][0]']                    \n",
      "                                                                                                  \n",
      " graph_layerg1 (Activation)     (None, 2700)         0           ['gcn_6[0][0]']                  \n",
      "                                                                                                  \n",
      " graph_layerb1 (Activation)     (None, 2700)         0           ['gcn_12[0][0]']                 \n",
      "                                                                                                  \n",
      " gcn_1 (GCN)                    (None, 2700)         21870000    ['graph_layerr1[0][0]']          \n",
      "                                                                                                  \n",
      " gcn_7 (GCN)                    (None, 2700)         21870000    ['graph_layerg1[0][0]']          \n",
      "                                                                                                  \n",
      " gcn_13 (GCN)                   (None, 2700)         21870000    ['graph_layerb1[0][0]']          \n",
      "                                                                                                  \n",
      " graph_layerr2 (Activation)     (None, 2700)         0           ['gcn_1[0][0]']                  \n",
      "                                                                                                  \n",
      " graph_layerg2 (Activation)     (None, 2700)         0           ['gcn_7[0][0]']                  \n",
      "                                                                                                  \n",
      " graph_layerb2 (Activation)     (None, 2700)         0           ['gcn_13[0][0]']                 \n",
      "                                                                                                  \n",
      " gcn_2 (GCN)                    (None, 2700)         21870000    ['graph_layerr2[0][0]']          \n",
      "                                                                                                  \n",
      " gcn_8 (GCN)                    (None, 2700)         21870000    ['graph_layerg2[0][0]']          \n",
      "                                                                                                  \n",
      " gcn_14 (GCN)                   (None, 2700)         21870000    ['graph_layerb2[0][0]']          \n",
      "                                                                                                  \n",
      " graph_layerr3 (Activation)     (None, 2700)         0           ['gcn_2[0][0]']                  \n",
      "                                                                                                  \n",
      " graph_layerg3 (Activation)     (None, 2700)         0           ['gcn_8[0][0]']                  \n",
      "                                                                                                  \n",
      " graph_layerb3 (Activation)     (None, 2700)         0           ['gcn_14[0][0]']                 \n",
      "                                                                                                  \n",
      " gcn_3 (GCN)                    (None, 2700)         21870000    ['graph_layerr3[0][0]']          \n",
      "                                                                                                  \n",
      " gcn_9 (GCN)                    (None, 2700)         21870000    ['graph_layerg3[0][0]']          \n",
      "                                                                                                  \n",
      " gcn_15 (GCN)                   (None, 2700)         21870000    ['graph_layerb3[0][0]']          \n",
      "                                                                                                  \n",
      " graph_layerr4 (Activation)     (None, 2700)         0           ['gcn_3[0][0]']                  \n",
      "                                                                                                  \n",
      " graph_layerg4 (Activation)     (None, 2700)         0           ['gcn_9[0][0]']                  \n",
      "                                                                                                  \n",
      " graph_layerb4 (Activation)     (None, 2700)         0           ['gcn_15[0][0]']                 \n",
      "                                                                                                  \n",
      " gcn_4 (GCN)                    (None, 2700)         21870000    ['graph_layerr4[0][0]']          \n",
      "                                                                                                  \n",
      " gcn_10 (GCN)                   (None, 2700)         21870000    ['graph_layerg4[0][0]']          \n",
      "                                                                                                  \n",
      " gcn_16 (GCN)                   (None, 2700)         21870000    ['graph_layerb4[0][0]']          \n",
      "                                                                                                  \n",
      " graph_layerr5 (Activation)     (None, 2700)         0           ['gcn_4[0][0]']                  \n",
      "                                                                                                  \n",
      " graph_layerg5 (Activation)     (None, 2700)         0           ['gcn_10[0][0]']                 \n",
      "                                                                                                  \n",
      " graph_layerb5 (Activation)     (None, 2700)         0           ['gcn_16[0][0]']                 \n",
      "                                                                                                  \n",
      " gcn_5 (GCN)                    (None, 2700)         21870000    ['graph_layerr5[0][0]']          \n",
      "                                                                                                  \n",
      " gcn_11 (GCN)                   (None, 2700)         21870000    ['graph_layerg5[0][0]']          \n",
      "                                                                                                  \n",
      " gcn_17 (GCN)                   (None, 2700)         21870000    ['graph_layerb5[0][0]']          \n",
      "                                                                                                  \n",
      " graph_layerr6 (Activation)     (None, 2700)         0           ['gcn_5[0][0]']                  \n",
      "                                                                                                  \n",
      " graph_layerg6 (Activation)     (None, 2700)         0           ['gcn_11[0][0]']                 \n",
      "                                                                                                  \n",
      " graph_layerb6 (Activation)     (None, 2700)         0           ['gcn_17[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 2700)        10800       ['graph_layerr6[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 2700)        10800       ['graph_layerg6[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 2700)        10800       ['graph_layerb6[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.stack (TFOpLambda)          (3, None, 2700)      0           ['batch_normalization[0][0]',    \n",
      "                                                                  'batch_normalization_1[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_1 (TFOp  (None, 2700, 3)     0           ['tf.stack[0][0]']               \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " denseshrink (Dense)            (None, 2700, 1)      4           ['tf.compat.v1.transpose_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOpLamb  (None, 2700)        0           ['denseshrink[0][0]']            \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " dense0 (Dense)                 (None, 64)           172864      ['tf.compat.v1.squeeze[0][0]']   \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 64)           4160        ['dense0[0][0]']                 \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 64)           4160        ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense3 (Dense)                 (None, 64)           4160        ['dense2[0][0]']                 \n",
      "                                                                                                  \n",
      " dense4 (Dense)                 (None, 64)           4160        ['dense3[0][0]']                 \n",
      "                                                                                                  \n",
      " dense5 (Dense)                 (None, 64)           4160        ['dense4[0][0]']                 \n",
      "                                                                                                  \n",
      " out_layer (Dense)              (None, 7)            455         ['dense5[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 393,886,523\n",
      "Trainable params: 393,870,323\n",
      "Non-trainable params: 16,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"mode/base_model\",\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/29 20:57:10 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '9b01295ecfdd4a61a82efe53c4d05c33', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 20:57:11.035762: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-06-29 20:57:11.675016: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-29 20:58:46.141113: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 - 102s - loss: 1.5445 - accuracy: 0.1662 - val_loss: 6.9435 - val_accuracy: 0.0861 - 102s/epoch - 970ms/step\n",
      "Epoch 2/15\n",
      "105/105 - 98s - loss: 1.4690 - accuracy: 0.1567 - val_loss: 82.5133 - val_accuracy: 0.0000e+00 - 98s/epoch - 933ms/step\n",
      "Epoch 3/15\n",
      "105/105 - 98s - loss: 1.4128 - accuracy: 0.1499 - val_loss: 4.9396 - val_accuracy: 0.0185 - 98s/epoch - 931ms/step\n",
      "Epoch 4/15\n",
      "105/105 - 98s - loss: 1.3287 - accuracy: 0.1540 - val_loss: 4.6814 - val_accuracy: 0.3444 - 98s/epoch - 931ms/step\n",
      "Epoch 5/15\n",
      "105/105 - 98s - loss: 1.2980 - accuracy: 0.1574 - val_loss: 4.1847 - val_accuracy: 0.3457 - 98s/epoch - 934ms/step\n",
      "Epoch 6/15\n",
      "105/105 - 101s - loss: 1.2173 - accuracy: 0.1576 - val_loss: 2.2406 - val_accuracy: 0.0172 - 101s/epoch - 963ms/step\n",
      "Epoch 7/15\n",
      "105/105 - 97s - loss: 1.1811 - accuracy: 0.1564 - val_loss: 3.9303 - val_accuracy: 0.0000e+00 - 97s/epoch - 925ms/step\n",
      "Epoch 8/15\n",
      "105/105 - 97s - loss: 1.1327 - accuracy: 0.1555 - val_loss: 2.3206 - val_accuracy: 0.0134 - 97s/epoch - 925ms/step\n",
      "Epoch 9/15\n",
      "105/105 - 97s - loss: 1.1325 - accuracy: 0.1655 - val_loss: 2.7905 - val_accuracy: 6.3776e-04 - 97s/epoch - 925ms/step\n",
      "Epoch 10/15\n",
      "105/105 - 102s - loss: 1.0634 - accuracy: 0.1673 - val_loss: 4.6270 - val_accuracy: 0.0000e+00 - 102s/epoch - 967ms/step\n",
      "Epoch 11/15\n",
      "105/105 - 97s - loss: 1.0222 - accuracy: 0.1653 - val_loss: 2.3833 - val_accuracy: 0.0000e+00 - 97s/epoch - 926ms/step\n",
      "Epoch 12/15\n",
      "105/105 - 97s - loss: 0.9892 - accuracy: 0.1626 - val_loss: 2.6541 - val_accuracy: 0.0102 - 97s/epoch - 926ms/step\n",
      "Epoch 13/15\n",
      "105/105 - 100s - loss: 0.9520 - accuracy: 0.1656 - val_loss: 4.9191 - val_accuracy: 0.2621 - 100s/epoch - 948ms/step\n",
      "Epoch 14/15\n",
      "105/105 - 97s - loss: 0.9672 - accuracy: 0.1598 - val_loss: 5.9595 - val_accuracy: 0.0019 - 97s/epoch - 926ms/step\n",
      "Epoch 15/15\n",
      "105/105 - 100s - loss: 0.9187 - accuracy: 0.1647 - val_loss: 2.5212 - val_accuracy: 0.0249 - 100s/epoch - 951ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 21:21:50.273265: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/v9/13sg2_p569zdm3chj4w3dmr00000gn/T/tmpfrd3ttua/model/data/model/assets\n"
     ]
    }
   ],
   "source": [
    "# with mlflow.start_run(nested=true):\n",
    "history = model.fit(x1,y1, batch_size=bs, epochs=15, callbacks=[callback],validation_data=(x2,y2),verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/ariqrahman/Desktop/Mac-Neural-Network-Project/model/base_model/gcn:v1/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/Users/ariqrahman/Desktop/Mac-Neural-Network-Project/model/base_model/gcn:v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=tf.keras.models.load_model(\"model/base_model/gcn1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"graph_neuralnetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_18 (InputLayer)          [(None, 9, 12, 3)]   0           []                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_16 (TFO  (3, None, 9, 12)    0           ['input_18[0][0]']               \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_156 (  (None, 9, 12)       0           ['tf.compat.v1.transpose_16[0][0]\n",
      " SlicingOpLambda)                                                ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_160 (  (None, 9, 12)       0           ['tf.compat.v1.transpose_16[0][0]\n",
      " SlicingOpLambda)                                                ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_164 (  (None, 9, 12)       0           ['tf.compat.v1.transpose_16[0][0]\n",
      " SlicingOpLambda)                                                ']                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_157 (  (None, 9, 12)       0           ['tf.__operators__.getitem_156[0]\n",
      " SlicingOpLambda)                                                [0]']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_161 (  (None, 9, 12)       0           ['tf.__operators__.getitem_160[0]\n",
      " SlicingOpLambda)                                                [0]']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_165 (  (None, 9, 12)       0           ['tf.__operators__.getitem_164[0]\n",
      " SlicingOpLambda)                                                [0]']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_158 (  (None, 9, 12)       0           ['tf.__operators__.getitem_157[0]\n",
      " SlicingOpLambda)                                                [0]']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_162 (  (None, 9, 12)       0           ['tf.__operators__.getitem_161[0]\n",
      " SlicingOpLambda)                                                [0]']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_166 (  (None, 9, 12)       0           ['tf.__operators__.getitem_165[0]\n",
      " SlicingOpLambda)                                                [0]']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_159 (  (None, 9, 12)       0           ['tf.__operators__.getitem_158[0]\n",
      " SlicingOpLambda)                                                [0]']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_163 (  (None, 9, 12)       0           ['tf.__operators__.getitem_162[0]\n",
      " SlicingOpLambda)                                                [0]']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_167 (  (None, 9, 12)       0           ['tf.__operators__.getitem_166[0]\n",
      " SlicingOpLambda)                                                [0]']                            \n",
      "                                                                                                  \n",
      " flatten_33 (Flatten)           (None, 108)          0           ['tf.__operators__.getitem_159[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " flatten_34 (Flatten)           (None, 108)          0           ['tf.__operators__.getitem_163[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " flatten_35 (Flatten)           (None, 108)          0           ['tf.__operators__.getitem_167[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " gcn_51 (GCN)                   (None, 108)          34992       ['flatten_33[0][0]']             \n",
      "                                                                                                  \n",
      " gcn_53 (GCN)                   (None, 108)          34992       ['flatten_34[0][0]']             \n",
      "                                                                                                  \n",
      " gcn_55 (GCN)                   (None, 108)          34992       ['flatten_35[0][0]']             \n",
      "                                                                                                  \n",
      " graph_layerr1 (Activation)     (None, 108)          0           ['gcn_51[0][0]']                 \n",
      "                                                                                                  \n",
      " graph_layerg1 (Activation)     (None, 108)          0           ['gcn_53[0][0]']                 \n",
      "                                                                                                  \n",
      " graph_layerb1 (Activation)     (None, 108)          0           ['gcn_55[0][0]']                 \n",
      "                                                                                                  \n",
      " gcn_52 (GCN)                   (None, 108)          34992       ['graph_layerr1[0][0]']          \n",
      "                                                                                                  \n",
      " gcn_54 (GCN)                   (None, 108)          34992       ['graph_layerg1[0][0]']          \n",
      "                                                                                                  \n",
      " gcn_56 (GCN)                   (None, 108)          34992       ['graph_layerb1[0][0]']          \n",
      "                                                                                                  \n",
      " graph_layerr2 (Activation)     (None, 108)          0           ['gcn_52[0][0]']                 \n",
      "                                                                                                  \n",
      " graph_layerg2 (Activation)     (None, 108)          0           ['gcn_54[0][0]']                 \n",
      "                                                                                                  \n",
      " graph_layerb2 (Activation)     (None, 108)          0           ['gcn_56[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 108)         432         ['graph_layerr2[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 108)         432         ['graph_layerg2[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 108)         432         ['graph_layerb2[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.stack_8 (TFOpLambda)        (3, None, 108)       0           ['batch_normalization_24[0][0]', \n",
      "                                                                  'batch_normalization_25[0][0]', \n",
      "                                                                  'batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_17 (TFO  (None, 108, 3)      0           ['tf.stack_8[0][0]']             \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " denseshrink (Dense)            (None, 108, 1)       4           ['tf.compat.v1.transpose_17[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_8 (TFOpLa  (None, 108)         0           ['denseshrink[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 32)           3488        ['tf.compat.v1.squeeze_8[0][0]'] \n",
      "                                                                                                  \n",
      " out_layer (Dense)              (None, 7)            231         ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 214,971\n",
      "Trainable params: 214,323\n",
      "Non-trainable params: 648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ccd6447379f5e6f7b170904fd40d7e61f0af72b45d9bab3c3472de833a965dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
